{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amandatz/NMF/blob/main/NMF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NMF"
      ],
      "metadata": {
        "id": "d8uJ7PpJCz5v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0ep9DvChlqxf"
      },
      "outputs": [],
      "source": [
        "using LinearAlgebra, Random, Plots, Statistics, Printf\n",
        "using Base.Threads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj8t-IqYmNU0",
        "outputId": "08392018-383d-41af-e148-feb9e82551d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TaskLocalRNG()"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "using Random\n",
        "Random.seed!(123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ETqjQrZJeOM"
      },
      "source": [
        "## Auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRt6JeaJVLYc",
        "outputId": "94afe950-aa98-4b6f-89f3-e62a6e2fcaca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0000000000000002e-6"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "max_iter_fixed = 100000\n",
        "tol_fixo = 1e-4\n",
        "tol_fixo_sub = tol_fixo*0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjgoj2_iJf-N",
        "outputId": "ffbda9ee-88b3-4957-d7a9-e19bfbcb3019"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "generate_X_WH (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "function generate_matrix(m, n; type=:uniform)\n",
        "    Q1 = qr(randn(m, m)).Q\n",
        "    Q2 = qr(randn(n, n)).Q\n",
        "    d = zeros(min(m, n))\n",
        "    kappa = 1e8\n",
        "\n",
        "    if type == :uniform\n",
        "        d .= rand(length(d))\n",
        "\n",
        "    elseif type == :decaying\n",
        "        d .= LinRange(1.0, 0.1, length(d))\n",
        "\n",
        "    elseif type == :equal\n",
        "        d .= ones(length(d))\n",
        "\n",
        "    elseif type == :ill_conditioned\n",
        "        d .= [1 / kappa^((i - 1) / (length(d) - 1)) for i in 1:length(d)]\n",
        "\n",
        "    else\n",
        "        error(\"Tipo inválido\")\n",
        "    end\n",
        "\n",
        "    X = abs.(Q1[:, 1:length(d)] * Diagonal(d) * Q2'[1:length(d), :])\n",
        "    return X\n",
        "end\n",
        "\n",
        "function generate_X_WH(m, n, r; type=:uniform)\n",
        "    W = generate_matrix(m, r; type=type)\n",
        "    H = generate_matrix(r, n; type=type)\n",
        "    X = W * H\n",
        "    return X, W, H\n",
        "end\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function lipschitz_step(A; eps = 1e-8)\n",
        "    L = opnorm(A) + eps\n",
        "    return 1 / L\n",
        "end\n",
        "\n",
        "function rule_lipschitz_W(W, H, GW, iter, alpha_prev)\n",
        "    return lipschitz_step(H * H')\n",
        "end\n",
        "\n",
        "function rule_lipschitz_H(W, H, GH, iter, alpha_prev)\n",
        "    return lipschitz_step(W' * W)\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chNpyuu1FGT5",
        "outputId": "eac12de2-46e0-4286-96ef-12e855e5f0f7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rule_lipschitz_H (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Armijo"
      ],
      "metadata": {
        "id": "s_lIerdh7FOC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Busca Linear de Armijo com Backtracking"
      ],
      "metadata": {
        "id": "_Ve9sIPE7C7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function armijo_step(\n",
        "    F_func, X, G;\n",
        "    alpha_init = 1e-3, beta = 0.5, c = 1e-4,\n",
        "    max_iter = 20, proj = identity\n",
        ")\n",
        "    alpha = alpha_init\n",
        "    F = F_func(X)\n",
        "    normG2 = norm(G)^2\n",
        "    for k = 1:max_iter\n",
        "        X_new = proj(X .- alpha .* G)\n",
        "        F_new = F_func(X_new)\n",
        "        if F_new <= F - c * alpha * normG2\n",
        "            return alpha\n",
        "        end\n",
        "        alpha *= beta\n",
        "    end\n",
        "    return alpha\n",
        "end\n",
        "\n",
        "function rule_armijo_W(W, H, GW, iter, alpha_prev)\n",
        "    F_func = Wt -> 0.5 * norm(X - Wt * H)^2\n",
        "    return armijo_step(F_func, W, GW; alpha_init=alpha_prev, proj=x->max.(x,0.0))\n",
        "end\n",
        "\n",
        "function rule_armijo_H(W, H, GH, iter, alpha_prev)\n",
        "    F_func = Ht -> 0.5 * norm(X - W * Ht)^2\n",
        "    return armijo_step(F_func, H, GH; alpha_init=alpha_prev, proj=x->max.(x,0.0))\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NCRmwDKFOYz",
        "outputId": "b65a0bd5-e874-40e2-fc3c-64ee5b825dbc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rule_armijo_H (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function rule_hybrid_H(W, H, GH, iter, alpha_prev)\n",
        "    alpha_lip = 1 / (opnorm(W' * W) + 1e-8)\n",
        "    F_func = Ht -> 0.5 * norm(X - W * Ht)^2\n",
        "    return armijo_step(F_func, H, GH;\n",
        "        alpha_init = alpha_lip,\n",
        "        proj = x -> max.(x, 0.0)\n",
        "    )\n",
        "end\n",
        "\n",
        "function rule_hybrid_W(W, H, GW, iter, alpha_prev)\n",
        "    alpha_lip = 1 / (opnorm(H * H') + 1e-8)\n",
        "    F_func = Wt -> 0.5 * norm(Wt * H - X)^2\n",
        "    return armijo_step(F_func, W, GW;\n",
        "        alpha_init = alpha_lip,\n",
        "        proj = x -> max.(x, 0.0)\n",
        "    )\n",
        "end\n",
        "\n",
        "function rule_hybrid_H(W, H, GH, iter, alpha_prev)\n",
        "    alpha_lip = 1 / (opnorm(W' * W) + 1e-8)\n",
        "    F_func = Ht -> 0.5 * norm(W * Ht - X)^2\n",
        "    return armijo_step(F_func, H, GH;\n",
        "        alpha_init = alpha_lip,\n",
        "        proj = x -> max.(x, 0.0)\n",
        "    )\n",
        "end\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6ByeJm-QJ7d",
        "outputId": "ffbf3ebc-a57d-43c8-bfc5-1c7be67cf9fe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rule_hybrid_H (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Barzilai–Borwein"
      ],
      "metadata": {
        "id": "3m28Iujy2Nyd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\alpha_k = \\frac{s_k^T s_k}{s_k^T y_k}  \n",
        "$$\n",
        "com\n",
        "$$\n",
        "s_k = x_k - x_{k-1} \\\\\n",
        "y_k = \\nabla f(x_k) - \\nabla f(x_{k-1})\n",
        "$$"
      ],
      "metadata": {
        "id": "Uf-ZA9c42ZAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# Regra passo espectral (Barzilai–Borwein)\n",
        "# ==========================================================\n",
        "function make_rule_spectral_W()\n",
        "    prev_W = nothing\n",
        "    prev_G = nothing\n",
        "\n",
        "    return (W, H, G, iter, alpha_prev) -> begin\n",
        "        alpha = alpha_prev\n",
        "        if prev_W !== nothing && prev_G !== nothing\n",
        "            s = W .- prev_W\n",
        "            y = G .- prev_G\n",
        "            den = sum(s .* y)\n",
        "            if den > 0 && isfinite(den)\n",
        "                alpha = clamp(sum(s .* s) / den, 1e-12, 1e12)\n",
        "            end\n",
        "        end\n",
        "        prev_W, prev_G = copy(W), copy(G)\n",
        "        return alpha\n",
        "    end\n",
        "end\n",
        "\n",
        "\n",
        "function make_rule_spectral_H()\n",
        "    prev_H = nothing\n",
        "    prev_G = nothing\n",
        "\n",
        "    return (W, H, G, iter, alpha_prev) -> begin\n",
        "        alpha = alpha_prev\n",
        "        if prev_H !== nothing && prev_G !== nothing\n",
        "            s = H .- prev_H\n",
        "            y = G .- prev_G\n",
        "            den = sum(s .* y)\n",
        "            if den > 0 && isfinite(den)\n",
        "                alpha = clamp(sum(s .* s) / den, 1e-12, 1e12)\n",
        "            end\n",
        "        end\n",
        "        prev_H, prev_G = copy(H), copy(G)\n",
        "        return alpha\n",
        "    end\n",
        "end\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVjs_vuDtJRK",
        "outputId": "356f2808-f65f-4fc0-eb42-745b92de869c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "make_rule_spectral_H (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outros métodos"
      ],
      "metadata": {
        "id": "QJNdJmPXT6If"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6XDhgUiPVeZ"
      },
      "source": [
        "### NMF Inversa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIWLW8RCJhq5",
        "outputId": "09fbbea1-097a-4fe7-d78b-bcabaef44755"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nmf_inverse (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "function nmf_inverse(X, r; alpha=0.1, max_iter=max_iter_fixed, tol=tol_fixo)\n",
        "    m, n = size(X)\n",
        "    W = max.(rand(m, r), 1e-4)\n",
        "    H = max.(rand(r, n), 1e-4)\n",
        "    errors = Float64[]\n",
        "\n",
        "    t_start = time()\n",
        "    iters = 0\n",
        "\n",
        "    for iter = 1:max_iter\n",
        "        W_old = copy(W); H_old = copy(H)\n",
        "\n",
        "        A = H * H' + alpha*I(r)\n",
        "        W = X * H' * inv(A)\n",
        "        W .= max.(W, 0.0)\n",
        "        H .= H .* ((W' * X) ./ max.(W' * W * H, 1e-8))\n",
        "        H .= max.(H, 0.0)\n",
        "        push!(errors, norm(X - W*H))\n",
        "\n",
        "        if norm(W - W_old) / max(1, norm(W_old)) < tol &&\n",
        "          norm(H - H_old) / max(1, norm(H_old)) < tol\n",
        "            break\n",
        "        end\n",
        "    end\n",
        "\n",
        "    t_end = time()\n",
        "    total_time = t_end - t_start\n",
        "\n",
        "    return W, H, errors, total_time, iters\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALFN95BjxGKD"
      },
      "source": [
        "### Gradiente Projetado (atualização simultânea)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSTNfgrWggcG"
      },
      "source": [
        "$W^{t}$ e $H^{t}$ calculados simultaneamente. Espera-se terminar ambas $W^{t}$ e $H^{t}$ para calcular $W^{t+1}$ e $H^{t+1}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGYhrPKQxFi7",
        "outputId": "1e9f8308-ac13-4a8f-bf28-1115382389a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nmf_pg_simultaneo (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "function nmf_pg_simultaneo(\n",
        "    X, r;\n",
        "    max_iter = max_iter_fixed,\n",
        "    tol = tol_fixo,\n",
        "    lambda = 0.0,\n",
        "    alpha_rule_W = (W,H,G,i,a)->a,\n",
        "    alpha_rule_H = (W,H,G,i,a)->a,\n",
        "    alphaW_init = 1e-3,\n",
        "    alphaH_init = 1e-3\n",
        ")\n",
        "    m, n = size(X)\n",
        "    W = max.(rand(m, r), 1e-4)\n",
        "    H = max.(rand(r, n), 1e-4)\n",
        "    errors = Float64[]\n",
        "    iters = 0\n",
        "\n",
        "    alphaW = alphaW_init\n",
        "    alphaH = alphaH_init\n",
        "\n",
        "    t_start = time()\n",
        "\n",
        "    for k = 1:max_iter\n",
        "        W_old = copy(W)\n",
        "        H_old = copy(H)\n",
        "\n",
        "        #task_W = Threads.@spawn begin\n",
        "            GW = W * (H * H') .- X * H' .+ lambda .* W\n",
        "            alphaW = alpha_rule_W(W, H, GW, k, alphaW)\n",
        "            W_new = max.(W .- alphaW .* GW, 0.0) #max.(W .- alphaW .* GW, 0.0), alphaW\n",
        "        #end\n",
        "\n",
        "        #task_H = Threads.@spawn begin\n",
        "            GH = (W' * W) * H .- W' * X .+ lambda .* H\n",
        "            alphaH = alpha_rule_H(W, H, GH, k, alphaH)\n",
        "            H_new = max.(H .- alphaH .* GH, 0.0) #max.(H .- alphaH .* GH, 0.0), alphaH\n",
        "        #end\n",
        "\n",
        "        #(W_new, alphaW) = fetch(task_W)\n",
        "        #(H_new, alphaH) = fetch(task_H)\n",
        "\n",
        "        W .= W_new\n",
        "        H .= H_new\n",
        "\n",
        "        push!(errors, norm(X - W * H))\n",
        "        iters = k\n",
        "\n",
        "        # Critério de parada\n",
        "        if norm(W - W_old) / max(1, norm(W_old)) < tol &&\n",
        "           norm(H - H_old) / max(1, norm(H_old)) < tol\n",
        "            break\n",
        "        end\n",
        "    end\n",
        "\n",
        "    total_time = time() - t_start\n",
        "    return W, H, errors, total_time, iters\n",
        "end\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkTyUPHZJnLF"
      },
      "source": [
        "## NMF Multiplicativo (Lee & Seung)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1efOp22JqfG",
        "outputId": "723e4815-6c33-4294-fc3b-a201cf0320d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nmf_multiplicative (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "function nmf_multiplicative(X, r; max_iter=max_iter_fixed, tol=tol_fixo)\n",
        "    m, n = size(X)\n",
        "    W = max.(rand(m, r), 1e-4)\n",
        "    H = max.(rand(r, n), 1e-4)\n",
        "    errors = Float64[]\n",
        "\n",
        "    t_start = time()\n",
        "    iters = 0\n",
        "\n",
        "    for iter = 1:max_iter\n",
        "        W_old = copy(W)\n",
        "        H_old = copy(H)\n",
        "\n",
        "        H .= H .* ((W' * X) ./ max.(W' * W * H, 1e-8))\n",
        "        H .= max.(H, 0.0)\n",
        "        W .= W .* ((X * H') ./ max.(W * (H * H'), 1e-8))\n",
        "        W .= max.(W, 0.0)\n",
        "\n",
        "        push!(errors, norm(X - W * H))\n",
        "        iters = iter\n",
        "\n",
        "        if norm(W - W_old) / max(1, norm(W_old)) < tol &&\n",
        "           norm(H - H_old) / max(1, norm(H_old)) < tol\n",
        "            break\n",
        "        end\n",
        "    end\n",
        "\n",
        "    t_end = time()\n",
        "    total_time = t_end - t_start\n",
        "    return W, H, errors, total_time, iters\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Minimização Alternada com Gradiente Projetado (Lin)"
      ],
      "metadata": {
        "id": "4EWN6PX1UbWk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MQI9znlnUax0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icLkSHEgRfgb"
      },
      "source": [
        "## Gradiente Projetado (gradiente do subproblema)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function line_search_segment!(\n",
        "    A_old, A_new, G, fixed_mat, f;\n",
        "    beta = 0.5,\n",
        "    sigma = 0.1,\n",
        "    theta_min = 1e-12,\n",
        "    monotone = true,\n",
        "    f_hist = nothing,\n",
        "    M_hist = 5 # número da memória\n",
        ")\n",
        "    # direcao\n",
        "    dW = A_new .- A_old\n",
        "    inner = sum(G .* dW)\n",
        "\n",
        "    # valor no ponto antigo\n",
        "    f_old = f(A_old, fixed_mat)\n",
        "\n",
        "    # se não-monotono, calcula máximo da janela\n",
        "    if monotone\n",
        "        f_ref = f_old\n",
        "    else\n",
        "        # inicializa histórico se necessário\n",
        "        if f_hist === nothing || isempty(f_hist)\n",
        "            f_hist = [f_old]\n",
        "        end\n",
        "\n",
        "        # referencia = maior valor recente\n",
        "        f_ref = maximum(f_hist)\n",
        "    end\n",
        "\n",
        "    # começa com passo cheio\n",
        "    theta = 1.0\n",
        "    f_new = f(A_new, fixed_mat)\n",
        "\n",
        "    # condicao geral\n",
        "    while f_new > f_ref - sigma * theta * inner\n",
        "        theta *= beta\n",
        "        if theta < theta_min\n",
        "            break\n",
        "        end\n",
        "        A_new .= A_old .+ theta .* dW\n",
        "        f_new = f(A_new, fixed_mat)\n",
        "    end\n",
        "\n",
        "    # se for não-monotono, atualiza histórico\n",
        "    if !monotone\n",
        "        push!(f_hist, f_new)\n",
        "        if length(f_hist) > M_hist\n",
        "            popfirst!(f_hist)  # mantém último M_hist valores\n",
        "        end\n",
        "    end\n",
        "\n",
        "    return A_new, theta, f_hist\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGek0SHeK8od",
        "outputId": "f1120f49-12b5-454f-8caa-fc470d1a096d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "line_search_segment! (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function projected_gradient_W(X, H, W0;\n",
        "    alpha_init = 1e-3,\n",
        "    lambda = 0.0,\n",
        "    tol = tol_fixo_sub,\n",
        "    max_iter = max_iter_fixed,\n",
        "    monotone = true,\n",
        "    alpha_rule_W = (W, H, G, iter, alpha_prev) -> alpha_prev\n",
        ")\n",
        "    W = copy(W0)\n",
        "    alpha = alpha_init\n",
        "    f_W(Wt,Ht) = 0.5 * norm(X - Wt*Ht)^2 + (lambda/2)*norm(Wt)^2\n",
        "    f_hist_W = nothing\n",
        "\n",
        "    for iter = 1:max_iter\n",
        "        W_old = copy(W)\n",
        "\n",
        "        GW = W * (H * H') .- X * H' .+ lambda .* W\n",
        "        alpha = alpha_rule_W(W, H, GW, iter, alpha)\n",
        "        W .= max.(W .- alpha .* GW, 0.0)\n",
        "\n",
        "        W_new, theta, new_f_hist_W = line_search_segment!(\n",
        "            W_old, W, GW, H, f_W;\n",
        "            monotone = monotone,\n",
        "            f_hist = f_hist_W,\n",
        "            M_hist = 5\n",
        "        )\n",
        "        W .= W_new\n",
        "        f_hist_W = new_f_hist_W\n",
        "\n",
        "        if norm(W - W_old) / max(1.0, norm(W_old)) < tol\n",
        "            return W, iter\n",
        "        end\n",
        "    end\n",
        "\n",
        "    return W, max_iter\n",
        "end\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# Subproblema para H\n",
        "# ==========================================================\n",
        "function projected_gradient_H(X, W, H0;\n",
        "    alpha_init = 1e-3,\n",
        "    lambda = 0.0,\n",
        "    tol = tol_fixo_sub,\n",
        "    max_iter = max_iter_fixed,\n",
        "    monotone = true,\n",
        "    alpha_rule_H = (W, H, G, iter, alpha_prev) -> alpha_prev\n",
        ")\n",
        "    H = copy(H0)\n",
        "    alpha = alpha_init\n",
        "    f_H(Ht, Wt) = 0.5 * norm(X - Wt * Ht)^2 + (lambda/2)*norm(Ht)^2\n",
        "    f_hist_H = nothing\n",
        "\n",
        "    for iter = 1:max_iter\n",
        "        H_old = copy(H)\n",
        "\n",
        "        GH = (W' * W) * H .- W' * X .+ lambda .* H\n",
        "        alpha = alpha_rule_H(W, H, GH, iter, alpha)\n",
        "        H .= max.(H .- alpha .* GH, 0.0)\n",
        "\n",
        "        H_new, theta, new_f_hist_H = line_search_segment!(\n",
        "            H_old, H, GH, W, f_H;\n",
        "            monotone = monotone,\n",
        "            f_hist = f_hist_H,\n",
        "            M_hist = 5\n",
        "        )\n",
        "        H .= H_new\n",
        "        f_hist_H = new_f_hist_H\n",
        "\n",
        "        if norm(H - H_old) / max(1.0, norm(H_old)) < tol\n",
        "            return H, iter\n",
        "        end\n",
        "    end\n",
        "\n",
        "    return H, max_iter\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-NQ_Hm5fOKa",
        "outputId": "cf9c28f5-82f8-4a5c-8f1f-85abec0ed215"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "projected_gradient_H (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function nmf_gradient_projected(\n",
        "    X, r;\n",
        "    max_iter = max_iter_fixed,\n",
        "    tol = tol_fixo,\n",
        "    alpha_init = 1e-3,\n",
        "    lambda = 0.0,\n",
        "    sub_max_iter = max_iter_fixed,\n",
        "    sub_tol = tol_fixo_sub,\n",
        "    monotone = true,\n",
        "    alpha_rule_W = (W, H, G, i, a) -> a,\n",
        "    alpha_rule_H = (W, H, G, i, a) -> a\n",
        ")\n",
        "    m, n = size(X)\n",
        "    W = max.(rand(m, r), 1e-4)\n",
        "    H = max.(rand(r, n), 1e-4)\n",
        "    errors = Float64[]\n",
        "\n",
        "    t_start = time()\n",
        "    total_sub_iters = 0\n",
        "\n",
        "    for iter = 1:max_iter\n",
        "        W_old = copy(W)\n",
        "        H_old = copy(H)\n",
        "\n",
        "        # --- Atualização de W ---\n",
        "        W, iter_W = projected_gradient_W(X, H, W;\n",
        "            alpha_init = alpha_init,\n",
        "            lambda = lambda,\n",
        "            tol = sub_tol,\n",
        "            max_iter = sub_max_iter,\n",
        "            monotone = monotone,\n",
        "            alpha_rule_W = alpha_rule_W\n",
        "        )\n",
        "        total_sub_iters += iter_W\n",
        "\n",
        "        # --- Atualização de H ---\n",
        "        H, iter_H = projected_gradient_H(X, W, H;\n",
        "            alpha_init = alpha_init,\n",
        "            lambda = lambda,\n",
        "            tol = sub_tol,\n",
        "            max_iter = sub_max_iter,\n",
        "            monotone = monotone,\n",
        "            alpha_rule_H = alpha_rule_H\n",
        "        )\n",
        "        total_sub_iters += iter_H\n",
        "\n",
        "        push!(errors, norm(X - W * H))\n",
        "\n",
        "        deltaW = norm(W - W_old) / max(1.0, norm(W_old))\n",
        "        deltaH = norm(H - H_old) / max(1.0, norm(H_old))\n",
        "        if deltaW < tol && deltaH < tol\n",
        "            break\n",
        "        end\n",
        "    end\n",
        "\n",
        "    total_time = time() - t_start\n",
        "    return W, H, errors, total_time, total_sub_iters\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz1scpIXydon",
        "outputId": "76d182de-5460-4d9f-92cb-175b19bbd4b7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nmf_gradient_projected (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aLTlTij0SpP3"
      },
      "outputs": [],
      "source": [
        "#function nmf_gradient_projected_(\n",
        "#  X, r;\n",
        "#  max_iter=max_iter_fixed,\n",
        "#  tol=tol_fixo,\n",
        "#  alpha_init=1e-3,\n",
        "#  lambda=0.0,\n",
        "#  alpha_rule_W = (W, H, GW, iter, alpha_prev) -> alpha_prev,\n",
        "#  alpha_rule_H = (W, H, GH, iter, alpha_prev) -> alpha_prev)\n",
        "#\n",
        "#    m, n = size(X)\n",
        "#    W = max.(rand(m, r), 1e-4)\n",
        "#    H = max.(rand(r, n), 1e-4)\n",
        "#    errors = Float64[]\n",
        "#\n",
        "#    alpha_W, alpha_H = alpha_init, alpha_init\n",
        "#\n",
        "#    t_start = time()\n",
        "#    iters = 0\n",
        "#\n",
        "#    for iter = 1:max_iter\n",
        "#        W_old = copy(W); H_old = copy(H)\n",
        "#\n",
        "#        # Atualização de W\n",
        "#        GW = W * (H * H') .- X * H' .+ lambda .* W\n",
        "#        alpha_W = alpha_rule_W(W, H, GW, iter, alpha_W)\n",
        "#        W .= max.(W .- alpha_W .* GW, 0.0)\n",
        "#\n",
        "#        # Atualização de H\n",
        "#        GH = (W' * W) * H .- W' * X .+ lambda .* H\n",
        "#        alpha_H = alpha_rule_H(W, H, GH, iter, alpha_H)\n",
        "#        H .= max.(H .- alpha_H .* GH, 0.0)\n",
        "#\n",
        "#        push!(errors, norm(X - W*H))\n",
        "#        iters = iter\n",
        "#\n",
        "#        if norm(W - W_old) / max(1, norm(W_old)) < tol &&\n",
        "#           norm(H - H_old) / max(1, norm(H_old)) < tol\n",
        "#            break\n",
        "#        end\n",
        "#    end\n",
        "#\n",
        "#    t_end = time()\n",
        "#    total_time = t_end - t_start\n",
        "#    return W, H, errors, total_time, iters\n",
        "#end\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvhkUW0snEW9"
      },
      "source": [
        "### Gradiente Projetado (atualização assíncrona)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVYxQjKxth0i"
      },
      "source": [
        "$W^{t}$ e $H^{t}$ calculados simultaneamente. Não se espera terminar ambas $W^{t}$ e $H^{t}$ para calcular $W^{t+1}$ e $H^{t+1}$. Nesse caso, pode ocorrer de várias iterações $W^t, ..., W^{t+1}$ usarem o mesmo $H^t$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBv71EkSnD1_",
        "outputId": "8092191e-2e11-4f54-d4cc-dc3d81764932"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nmf_pg_async (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "function nmf_pg_async(\n",
        "    X, r;\n",
        "    max_iter = 5000,\n",
        "    tol = 1e-4,\n",
        "    lambda = 0.0,\n",
        "    alpha_rule_W = (W,H,G,i,a)->a,\n",
        "    alpha_rule_H = (W,H,G,i,a)->a,\n",
        "    alphaW_init = 1e-3,\n",
        "    alphaH_init = 1e-3\n",
        ")\n",
        "    m, n = size(X)\n",
        "    W = max.(rand(m, r), 1e-4)\n",
        "    H = max.(rand(r, n), 1e-4)\n",
        "    errors = Float64[]\n",
        "\n",
        "    lockW = ReentrantLock()\n",
        "    lockH = ReentrantLock()\n",
        "\n",
        "    stop_flag = Ref(false)\n",
        "    iter = Ref(0)\n",
        "\n",
        "    alphaW = alphaW_init\n",
        "    alphaH = alphaH_init\n",
        "\n",
        "    t_start = time()\n",
        "\n",
        "    # Atualiza W\n",
        "    taskW = Threads.@spawn begin\n",
        "        while !stop_flag[] && iter[] < max_iter\n",
        "            iter[] += 1\n",
        "\n",
        "            lock(lockH)\n",
        "            local H_local = copy(H)\n",
        "            unlock(lockH)\n",
        "\n",
        "            lock(lockW)\n",
        "            GW = W * H_local * H_local' .- X * H_local' .+ lambda .* W\n",
        "            alphaW = alpha_rule_W(W, H_local, GW, iter[], alphaW)\n",
        "            W_new = max.(W .- alphaW .* GW, 0.0)\n",
        "            ΔW = norm(W_new - W) / max(1, norm(W))\n",
        "            W .= W_new\n",
        "            unlock(lockW)\n",
        "\n",
        "            if ΔW < tol\n",
        "                stop_flag[] = true\n",
        "            end\n",
        "        end\n",
        "    end\n",
        "\n",
        "    # Atualiza H\n",
        "    taskH = Threads.@spawn begin\n",
        "        while !stop_flag[] && iter[] < max_iter\n",
        "            lock(lockW)\n",
        "            local W_local = copy(W)\n",
        "            unlock(lockW)\n",
        "\n",
        "            lock(lockH)\n",
        "            GH = (W_local' * W_local) * H .- W_local' * X .+ lambda .* H\n",
        "            alphaH = alpha_rule_H(W_local, H, GH, iter[], alphaH)\n",
        "            H_new = max.(H .- alphaH .* GH, 0.0)\n",
        "            ΔH = norm(H_new - H) / max(1, norm(H))\n",
        "            H .= H_new\n",
        "            unlock(lockH)\n",
        "\n",
        "            if ΔH < tol\n",
        "                stop_flag[] = true\n",
        "            end\n",
        "        end\n",
        "    end\n",
        "\n",
        "    # Monitora erro periodicamente\n",
        "    while !stop_flag[] && iter[] < max_iter\n",
        "        sleep(0.01)\n",
        "        lock(lockW); lock(lockH)\n",
        "        push!(errors, norm(X - W * H))\n",
        "        unlock(lockH); unlock(lockW)\n",
        "    end\n",
        "\n",
        "    total_time = time() - t_start\n",
        "    fetch(taskW); fetch(taskH)\n",
        "\n",
        "    return W, H, errors, total_time, iter[]\n",
        "end\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWz8--_jnqX_",
        "outputId": "0a5e7458-a4ad-42ee-b945-fbb3cfde5d49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threads disponíveis: 2\n",
            "Erro final = 2.3924952525474725\n",
            "Tempo total = 3.232 s\n",
            "Iterações ≈ 962\n"
          ]
        }
      ],
      "source": [
        "println(\"Threads disponíveis: \", Threads.nthreads())\n",
        "\n",
        "X = rand(10, 10)\n",
        "W, H, errors, t, iters = nmf_pg_async(X, 2;)\n",
        "println(\"Erro final = $(errors[end])\")\n",
        "println(\"Tempo total = $(round(t, digits=3)) s\")\n",
        "println(\"Iterações ≈ $iters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6uDFFYZSofZ"
      },
      "source": [
        "## Testes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEvZ4HjSGCwy",
        "outputId": "cf9a85b1-aab3-4a1a-d9e9-2fa231028099"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dict{Symbol, Function} with 3 entries:\n",
              "  :gradiente_projetado_spectral_monotone     => #79\n",
              "  :multiplicativo                            => nmf_multiplicative\n",
              "  :gradiente_projetado_spectral_non_monotone => #77"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "dims = [100, 1000]\n",
        "r_values = [5, 10, 20]\n",
        "types = [:equal, :ill_conditioned]\n",
        "\n",
        "#dims = [1000]\n",
        "#r_values = [5, 100, 500]\n",
        "#types = [:equal, :ill_conditioned]\n",
        "\n",
        "models = Dict{Symbol, Function}(\n",
        "    #:inversa => nmf_inverse,\n",
        "\n",
        "    # ------------\n",
        "    :multiplicativo => nmf_multiplicative,\n",
        "\n",
        "    # ------------\n",
        "    #:gradiente_projetado => (X, r; kwargs...) -> nmf_gradient_projected( # passo fixo\n",
        "    #    X, r; alpha_rule_W = (W,H,G,i,a)->a, alpha_rule_H = (W,H,G,i,a)->a, kwargs...\n",
        "    #),\n",
        "\n",
        "    #:gradiente_projetado_lipschitz => (X, r; kwargs...) -> nmf_gradient_projected( # Lipschitz\n",
        "    #    X, r; alpha_rule_W = rule_lipschitz_W, alpha_rule_H = rule_lipschitz_H, kwargs...\n",
        "    #),\n",
        "\n",
        "    #:gradiente_projetado_armijo => (X, r; kwargs...) -> nmf_gradient_projected( # Armijo\n",
        "    #    X, r; alpha_rule_W = rule_armijo_W, alpha_rule_H = rule_armijo_H, kwargs...\n",
        "    #),\n",
        "\n",
        "    :gradiente_projetado_spectral_non_monotone => (X, r; kwargs...) -> nmf_gradient_projected(\n",
        "        X, r;\n",
        "        alpha_rule_W = make_rule_spectral_W(),\n",
        "        alpha_rule_H = make_rule_spectral_H(),\n",
        "        monotone = false,\n",
        "        kwargs...\n",
        "    ),\n",
        "\n",
        "    :gradiente_projetado_spectral_monotone => (X, r; kwargs...) -> nmf_gradient_projected(\n",
        "        X, r;\n",
        "        alpha_rule_W = make_rule_spectral_W(),\n",
        "        alpha_rule_H = make_rule_spectral_H(),\n",
        "        monotone = true,\n",
        "        kwargs...\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrizes aleatórias $X, W, H$"
      ],
      "metadata": {
        "id": "N0pA3twwII4a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zZpTP2rGWbj",
        "outputId": "0a214e85-df1e-40f9-d54f-77826c573ab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Dimension = 100 | rank = 5 | type = equal ===\n",
            "gradiente_projetado_spectral_monotone → Erro final: 5.568861531982 | Iterações: 502 | Tempo: 4.1235s\n",
            "multiplicativo → Erro final: 5.550016565382152 | Iterações: 1922 | Tempo: 0.2146s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 5.585246024075872 | Iterações: 296 | Tempo: 0.0578s\n",
            "\n",
            "=== Dimension = 100 | rank = 5 | type = ill_conditioned ===\n",
            "gradiente_projetado_spectral_monotone → Erro final: 0.8055070371867611 | Iterações: 160 | Tempo: 0.0304s\n",
            "multiplicativo → Erro final: 0.7778718260148995 | Iterações: 1021 | Tempo: 0.112s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 0.7831729286922701 | Iterações: 307 | Tempo: 0.0543s\n",
            "\n",
            "=== Dimension = 100 | rank = 10 | type = equal ===\n",
            "gradiente_projetado_spectral_monotone → Erro final: 5.153741144712263 | Iterações: 921 | Tempo: 0.1817s\n",
            "multiplicativo → Erro final: 5.134837090487826 | Iterações: 1759 | Tempo: 0.22s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 5.171340690025527 | Iterações: 650 | Tempo: 0.1142s\n",
            "\n",
            "=== Dimension = 100 | rank = 10 | type = ill_conditioned ===\n",
            "gradiente_projetado_spectral_monotone → Erro final: 0.6865032765600292 | Iterações: 220 | Tempo: 0.0473s\n",
            "multiplicativo → Erro final: 0.6345931823872277 | Iterações: 929 | Tempo: 0.1084s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 0.6866164715158664 | Iterações: 227 | Tempo: 0.0407s\n",
            "\n",
            "=== Dimension = 100 | rank = 20 | type = equal ===\n",
            "gradiente_projetado_spectral_monotone → Erro final: 4.5886077915148284 | Iterações: 512 | Tempo: 0.1432s\n",
            "multiplicativo → Erro final: 4.469397657389707 | Iterações: 3149 | Tempo: 0.5963s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 4.578674806572749 | Iterações: 645 | Tempo: 0.1466s\n",
            "\n",
            "=== Dimension = 100 | rank = 20 | type = ill_conditioned ===\n",
            "gradiente_projetado_spectral_monotone → Erro final: 0.6457454469249291 | Iterações: 302 | Tempo: 0.0789s\n",
            "multiplicativo → Erro final: 0.47538839444507935 | Iterações: 2035 | Tempo: 0.3677s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 0.5552790727126766 | Iterações: 1000 | Tempo: 0.2503s\n",
            "\n",
            "=== Dimension = 1000 | rank = 5 | type = equal ===\n",
            "gradiente_projetado_spectral_monotone → Erro final: 18.932463341640673 | Iterações: 246 | Tempo: 7.5173s\n",
            "multiplicativo → Erro final: 18.89299384322133 | Iterações: 1465 | Tempo: 20.9475s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 18.902693330506768 | Iterações: 557 | Tempo: 13.8786s\n",
            "\n",
            "=== Dimension = 1000 | rank = 5 | type = ill_conditioned ===\n",
            "gradiente_projetado_spectral_monotone → Erro final: 3.1208158151912055 | Iterações: 160 | Tempo: 4.013s\n",
            "multiplicativo → Erro final: 3.105247171614072 | Iterações: 1331 | Tempo: 16.2404s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 3.1203839729691376 | Iterações: 129 | Tempo: 3.3182s\n",
            "\n",
            "=== Dimension = 1000 | rank = 10 | type = equal ===\n",
            "gradiente_projetado_spectral_monotone → Erro final: 18.799627686605458 | Iterações: 257 | Tempo: 6.2883s\n",
            "multiplicativo → Erro final: 18.7283335597871 | Iterações: 2157 | Tempo: 28.4897s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 18.754135955906442 | Iterações: 468 | Tempo: 10.0951s\n",
            "\n",
            "=== Dimension = 1000 | rank = 10 | type = ill_conditioned ===\n",
            "gradiente_projetado_spectral_monotone → Erro final: 3.0865479557521724 | Iterações: 225 | Tempo: 5.2068s\n",
            "multiplicativo → Erro final: 3.068370680302391 | Iterações: 2283 | Tempo: 26.5137s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 3.097058952210481 | Iterações: 127 | Tempo: 2.1988s\n",
            "\n",
            "=== Dimension = 1000 | rank = 20 | type = equal ===\n",
            "gradiente_projetado_spectral_monotone → Erro final: 18.533062272439942 | Iterações: 376 | Tempo: 10.856s\n",
            "multiplicativo → Erro final: 18.43760823648935 | Iterações: 2834 | Tempo: 39.0233s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 18.472379035513555 | Iterações: 100625 | Tempo: 2216.5397s\n",
            "\n",
            "=== Dimension = 1000 | rank = 20 | type = ill_conditioned ===\n",
            "gradiente_projetado_spectral_monotone → Erro final: 3.054074830806471 | Iterações: 160 | Tempo: 4.6833s\n",
            "multiplicativo → Erro final: 2.9978717906718555 | Iterações: 2759 | Tempo: 41.8214s\n"
          ]
        }
      ],
      "source": [
        "for n in dims\n",
        "    for r in r_values\n",
        "        if r > n\n",
        "            continue\n",
        "        end\n",
        "\n",
        "        for t in types\n",
        "            println(\"\\n=== Dimension = $n | rank = $r | type = $t ===\")\n",
        "            X = generate_matrix(n,n, type=t)\n",
        "\n",
        "            for (name, model) in models\n",
        "                W, H, err, total_time, iters = model(X, r)\n",
        "\n",
        "                erro_final = isempty(err) ? NaN : err[end]\n",
        "                tempo = round(total_time, digits=4)\n",
        "\n",
        "                println(\"$(string(name)) → Erro final: $erro_final | Iterações: $iters | Tempo: $(tempo)s\")\n",
        "            end\n",
        "        end\n",
        "    end\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Teste exato $X = WH$"
      ],
      "metadata": {
        "id": "7p8B2s6rLtxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dims = [10, 100, 1000]\n",
        "r_values = [10]\n",
        "types = [:equal]\n",
        "\n",
        "for n in dims\n",
        "    for r in r_values\n",
        "        if r > n\n",
        "            continue\n",
        "        end\n",
        "\n",
        "        for t in types\n",
        "            println(\"\\n=== Dimension = $n | rank = $r | type = $t ===\")\n",
        "            X, W_true, H_true = generate_X_WH(n, n, r; type=t)\n",
        "\n",
        "            for (name, model) in models\n",
        "                W, H, err, total_time, iters = model(X, r)\n",
        "\n",
        "                erro_final = isempty(err) ? NaN : err[end]\n",
        "                tempo = round(total_time, digits=4)\n",
        "\n",
        "                err_WH = norm(X - W * H) / norm(X)\n",
        "                err_W  = norm(W - W_true) / norm(W_true)\n",
        "                err_H  = norm(H - H_true) / norm(H_true)\n",
        "                println(\"$(string(name)) → Erro(X): $(round(err_WH,digits=6)) | Erro(W): $(round(err_W,digits=6)) | Erro(H): $(round(err_H,digits=6)) | Iterações: $iters | Tempo: $(tempo)s\")\n",
        "            end\n",
        "        end\n",
        "    end\n",
        "end"
      ],
      "metadata": {
        "id": "gSiYKxSIL_VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYMC_nUdJBSC"
      },
      "outputs": [],
      "source": [
        "num_trials = 10\n",
        "dims = [200]\n",
        "r = 10\n",
        "type = :uniform\n",
        "\n",
        "for n in dims\n",
        "    println(\"\\n===============================\")\n",
        "    println(\"=== Dimensão = $n | rank = $r | tipo = $type ===\")\n",
        "    println(\"===============================\")\n",
        "\n",
        "    # inicializa dicionários\n",
        "    errors = Dict(model => [] for model in keys(models))\n",
        "    times  = Dict(model => Float64[] for model in keys(models))\n",
        "    iters  = Dict(model => Int[] for model in keys(models))\n",
        "\n",
        "    # ----------------------------------------------------------\n",
        "    # Loop principal\n",
        "    # ----------------------------------------------------------\n",
        "    for trial in 1:num_trials\n",
        "        print(\"$trial, \")\n",
        "        X = generate_matrix(n, n, type=type)\n",
        "\n",
        "        for (name, model) in models\n",
        "            t_start = time()\n",
        "            _, _, err = model(X, r)\n",
        "            t_end = time()\n",
        "\n",
        "            push!(errors[name], err)\n",
        "            push!(times[name], t_end - t_start)\n",
        "            push!(iters[name], length(err))\n",
        "        end\n",
        "    end\n",
        "    println(\"\\n\")\n",
        "\n",
        "    # ----------------------------------------------------------\n",
        "    # Estatísticas de erro final\n",
        "    # ----------------------------------------------------------\n",
        "    println(\"=== Estatísticas do erro final (n = $n) ===\")\n",
        "    for name in keys(models)\n",
        "        final_errs = [isempty(e) ? NaN : e[end] for e in errors[name]]\n",
        "        media = mean(skipmissing(final_errs))\n",
        "        desvio = std(skipmissing(final_errs))\n",
        "        @printf(\"%-35s → Média = %.6f | Std = %.6f\\n\", string(name), media, desvio)\n",
        "    end\n",
        "\n",
        "    # ----------------------------------------------------------\n",
        "    # Estatísticas de tempo\n",
        "    # ----------------------------------------------------------\n",
        "    println(\"\\n=== Estatísticas de tempo (n = $n) ===\")\n",
        "    for name in keys(models)\n",
        "        media = mean(times[name])\n",
        "        desvio = std(times[name])\n",
        "        @printf(\"%-35s → Média = %.6fs | Std = %.6fs\\n\", string(name), media, desvio)\n",
        "    end\n",
        "\n",
        "    # ----------------------------------------------------------\n",
        "    # Estatísticas de iterações\n",
        "    # ----------------------------------------------------------\n",
        "    println(\"\\n=== Estatísticas do número de iterações (n = $n) ===\")\n",
        "    for name in keys(models)\n",
        "        media = mean(iters[name])\n",
        "        desvio = std(iters[name])\n",
        "        @printf(\"%-35s → Média = %.2f | Std = %.2f\\n\", string(name), media, desvio)\n",
        "    end\n",
        "end\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEtJNu32HDTx"
      },
      "source": [
        "# NMF package"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## https://nimfa.biolab.si/nimfa.datasets.html"
      ],
      "metadata": {
        "id": "VAKuExZ3sqJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRHpk7ZNHCr2",
        "outputId": "fce2e77f-cab5-4adc-82d3-d0a34b716598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m\u001b[1m     Cloning\u001b[22m\u001b[39m git-repo `https://github.com/JuliaStats/NMF.jl`\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaStats/NMF.jl`\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m NonNegLeastSquares ─ v0.4.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m RandomizedLinAlg ─── v0.1.0\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.11/Project.toml`\n",
            "  \u001b[90m[6ef6ca0d] \u001b[39m\u001b[92m+ NMF v1.0.3 `https://github.com/JuliaStats/NMF.jl#master`\u001b[39m\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.11/Manifest.toml`\n",
            "  \u001b[90m[6ef6ca0d] \u001b[39m\u001b[92m+ NMF v1.0.3 `https://github.com/JuliaStats/NMF.jl#master`\u001b[39m\n",
            "  \u001b[90m[b7351bd1] \u001b[39m\u001b[92m+ NonNegLeastSquares v0.4.1\u001b[39m\n",
            "  \u001b[90m[0448d7d9] \u001b[39m\u001b[92m+ RandomizedLinAlg v0.1.0\u001b[39m\n",
            "\u001b[92m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "   4984.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mNonNegLeastSquares\u001b[39m\n",
            "   3881.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mRandomizedLinAlg\u001b[39m\n",
            "  42869.2 ms\u001b[32m  ✓ \u001b[39mNMF\n",
            "  3 dependencies successfully precompiled in 55 seconds. 490 already precompiled.\n"
          ]
        }
      ],
      "source": [
        "using Pkg\n",
        "Pkg.add(url=\"https://github.com/JuliaStats/NMF.jl\")\n",
        "using NMF\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "http://mtm.ufsc.br/~douglas/2019.1/MTM5813/matlab/"
      ],
      "metadata": {
        "id": "w6ugqYQseZlO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "41lLifSQeaFR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_6XDhgUiPVeZ",
        "KkTyUPHZJnLF",
        "ALFN95BjxGKD",
        "vvhkUW0snEW9"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Julia",
      "name": "julia"
    },
    "language_info": {
      "name": "julia"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}