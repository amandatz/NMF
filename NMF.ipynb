{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amandatz/NMF/blob/main/NMF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NMF"
      ],
      "metadata": {
        "id": "d8uJ7PpJCz5v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0ep9DvChlqxf"
      },
      "outputs": [],
      "source": [
        "using LinearAlgebra, Random, Plots, Statistics, Printf\n",
        "using Base.Threads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj8t-IqYmNU0",
        "outputId": "ee159a88-8b98-43e5-e2a2-db39abd68add"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TaskLocalRNG()"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "using Random\n",
        "Random.seed!(123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ETqjQrZJeOM"
      },
      "source": [
        "## Auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRt6JeaJVLYc",
        "outputId": "633accb5-8841-4de9-f3af-56418b7c4484"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0000000000000002e-6"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "max_iter_fixed = 100000\n",
        "tol_fixo = 1e-4\n",
        "tol_fixo_sub = tol_fixo*0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjgoj2_iJf-N",
        "outputId": "30a7ce6a-ecca-464b-8322-24c17c6ba185"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "generate_X_WH (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "function generate_matrix(m, n; type=:uniform)\n",
        "    Q1 = qr(randn(m, m)).Q\n",
        "    Q2 = qr(randn(n, n)).Q\n",
        "    d = zeros(min(m, n))\n",
        "    kappa = 1e8\n",
        "\n",
        "    if type == :uniform\n",
        "        d .= rand(length(d))\n",
        "\n",
        "    elseif type == :decaying\n",
        "        d .= LinRange(1.0, 0.1, length(d))\n",
        "\n",
        "    elseif type == :equal\n",
        "        d .= ones(length(d))\n",
        "\n",
        "    elseif type == :ill_conditioned\n",
        "        d .= [1 / kappa^((i - 1) / (length(d) - 1)) for i in 1:length(d)]\n",
        "\n",
        "    else\n",
        "        error(\"Tipo inválido\")\n",
        "    end\n",
        "\n",
        "    X = abs.(Q1[:, 1:length(d)] * Diagonal(d) * Q2'[1:length(d), :])\n",
        "    return X\n",
        "end\n",
        "\n",
        "function generate_X_WH(m, n, r; type=:uniform)\n",
        "    W = generate_matrix(m, r; type=type)\n",
        "    H = generate_matrix(r, n; type=type)\n",
        "    X = W * H\n",
        "    return X, W, H\n",
        "end\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function lipschitz_step(A; eps = 1e-8)\n",
        "    L = opnorm(A) + eps\n",
        "    return 1 / L\n",
        "end\n",
        "\n",
        "function rule_lipschitz_W(W, H, GW, iter, alpha_prev)\n",
        "    return lipschitz_step(H * H')\n",
        "end\n",
        "\n",
        "function rule_lipschitz_H(W, H, GH, iter, alpha_prev)\n",
        "    return lipschitz_step(W' * W)\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chNpyuu1FGT5",
        "outputId": "f68040e8-7ad6-4591-f73a-4c264d9a2037"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rule_lipschitz_H (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Minimização Alternada"
      ],
      "metadata": {
        "id": "xqoQBmwy2qYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function minimizacao_alternada(\n",
        "    X, r,\n",
        "    W_init, H_init;\n",
        "    update_W_func,   # Função que resolve subproblema em W\n",
        "    update_H_func,   # Função que resolve subproblema em H\n",
        "    max_iter = max_iter_fixed,\n",
        "    tol = tol_fixo\n",
        ")\n",
        "    m, n = size(X)\n",
        "\n",
        "    # Inicialização das matrizes\n",
        "    W = isnothing(W_init) ? max.(rand(m, r), 1e-4) : copy(W_init)\n",
        "    H = isnothing(H_init) ? max.(rand(r, n), 1e-4) : copy(H_init)\n",
        "\n",
        "    errors = Float64[]\n",
        "    t_start = time()\n",
        "    total_sub_iters = 0\n",
        "\n",
        "    for iter = 1:max_iter\n",
        "        W_old = copy(W)\n",
        "        H_old = copy(H)\n",
        "\n",
        "        # --- Atualização de W (Fixa H) ---\n",
        "        # A função deve retornar (W_novo, sub_iters)\n",
        "        W, iter_W = update_W_func(X, W, H)\n",
        "        total_sub_iters += iter_W\n",
        "\n",
        "        # --- Atualização de H (Fixa W) ---\n",
        "        # A função deve retornar (H_novo, sub_iters)\n",
        "        H, iter_H = update_H_func(X, W, H)\n",
        "        total_sub_iters += iter_H\n",
        "\n",
        "        # Cálculo do erro de reconstrução\n",
        "        push!(errors, norm(X - W * H))\n",
        "\n",
        "        # Critério de parada baseado na variação relativa das matrizes\n",
        "        deltaW = norm(W - W_old) / max(1.0, norm(W_old))\n",
        "        deltaH = norm(H - H_old) / max(1.0, norm(H_old))\n",
        "\n",
        "        if deltaW < tol && deltaH < tol\n",
        "            break\n",
        "        end\n",
        "    end\n",
        "\n",
        "    total_time = time() - t_start\n",
        "    return W, H, errors, total_time, total_sub_iters\n",
        "end"
      ],
      "metadata": {
        "id": "GDW6zi0P2r96",
        "outputId": "1be64d1c-718f-4342-a2e5-83dfa30092ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "minimizacao_alternada (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Armijo"
      ],
      "metadata": {
        "id": "s_lIerdh7FOC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Busca Linear de Armijo com Backtracking"
      ],
      "metadata": {
        "id": "_Ve9sIPE7C7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function armijo_step(\n",
        "    F_func, X, G;\n",
        "    alpha_init = 1e-3, beta = 0.5, c = 1e-4,\n",
        "    max_iter = 20, proj = identity\n",
        ")\n",
        "    alpha = alpha_init\n",
        "    F = F_func(X)\n",
        "    normG2 = norm(G)^2\n",
        "    for k = 1:max_iter\n",
        "        X_new = proj(X .- alpha .* G)\n",
        "        F_new = F_func(X_new)\n",
        "        if F_new <= F - c * alpha * normG2\n",
        "            return alpha\n",
        "        end\n",
        "        alpha *= beta\n",
        "    end\n",
        "    return alpha\n",
        "end\n",
        "\n",
        "function rule_armijo_W(W, H, GW, iter, alpha_prev)\n",
        "    F_func = Wt -> 0.5 * norm(X - Wt * H)^2\n",
        "    return armijo_step(F_func, W, GW; alpha_init=alpha_prev, proj=x->max.(x,0.0))\n",
        "end\n",
        "\n",
        "function rule_armijo_H(W, H, GH, iter, alpha_prev)\n",
        "    F_func = Ht -> 0.5 * norm(X - W * Ht)^2\n",
        "    return armijo_step(F_func, H, GH; alpha_init=alpha_prev, proj=x->max.(x,0.0))\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NCRmwDKFOYz",
        "outputId": "b9e70b35-3453-433b-c4cc-fd95b3f4ab43"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rule_armijo_H (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function rule_hybrid_H(W, H, GH, iter, alpha_prev)\n",
        "    alpha_lip = 1 / (opnorm(W' * W) + 1e-8)\n",
        "    F_func = Ht -> 0.5 * norm(X - W * Ht)^2\n",
        "    return armijo_step(F_func, H, GH;\n",
        "        alpha_init = alpha_lip,\n",
        "        proj = x -> max.(x, 0.0)\n",
        "    )\n",
        "end\n",
        "\n",
        "function rule_hybrid_W(W, H, GW, iter, alpha_prev)\n",
        "    alpha_lip = 1 / (opnorm(H * H') + 1e-8)\n",
        "    F_func = Wt -> 0.5 * norm(Wt * H - X)^2\n",
        "    return armijo_step(F_func, W, GW;\n",
        "        alpha_init = alpha_lip,\n",
        "        proj = x -> max.(x, 0.0)\n",
        "    )\n",
        "end\n",
        "\n",
        "function rule_hybrid_H(W, H, GH, iter, alpha_prev)\n",
        "    alpha_lip = 1 / (opnorm(W' * W) + 1e-8)\n",
        "    F_func = Ht -> 0.5 * norm(W * Ht - X)^2\n",
        "    return armijo_step(F_func, H, GH;\n",
        "        alpha_init = alpha_lip,\n",
        "        proj = x -> max.(x, 0.0)\n",
        "    )\n",
        "end\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6ByeJm-QJ7d",
        "outputId": "e3d4f8d5-7dd7-481c-da99-e90e0fbd11b3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rule_hybrid_H (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Barzilai–Borwein"
      ],
      "metadata": {
        "id": "3m28Iujy2Nyd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\alpha_k = \\frac{s_k^T s_k}{s_k^T y_k}  \n",
        "$$\n",
        "com\n",
        "$$\n",
        "s_k = x_k - x_{k-1} \\\\\n",
        "y_k = \\nabla f(x_k) - \\nabla f(x_{k-1})\n",
        "$$"
      ],
      "metadata": {
        "id": "Uf-ZA9c42ZAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# Regra passo espectral (Barzilai–Borwein)\n",
        "# ==========================================================\n",
        "function make_rule_spectral_W()\n",
        "    prev_W = nothing\n",
        "    prev_G = nothing\n",
        "\n",
        "    return (W, H, G, iter, alpha_prev) -> begin\n",
        "        alpha = alpha_prev\n",
        "        if prev_W !== nothing && prev_G !== nothing\n",
        "            s = W .- prev_W\n",
        "            y = G .- prev_G\n",
        "            den = sum(s .* y)\n",
        "            if den > 0 && isfinite(den)\n",
        "                alpha = clamp(sum(s .* s) / den, 1e-12, 1e12)\n",
        "            end\n",
        "        end\n",
        "        prev_W, prev_G = copy(W), copy(G)\n",
        "        return alpha\n",
        "    end\n",
        "end\n",
        "\n",
        "\n",
        "function make_rule_spectral_H()\n",
        "    prev_H = nothing\n",
        "    prev_G = nothing\n",
        "\n",
        "    return (W, H, G, iter, alpha_prev) -> begin\n",
        "        alpha = alpha_prev\n",
        "        if prev_H !== nothing && prev_G !== nothing\n",
        "            s = H .- prev_H\n",
        "            y = G .- prev_G\n",
        "            den = sum(s .* y)\n",
        "            if den > 0 && isfinite(den)\n",
        "                alpha = clamp(sum(s .* s) / den, 1e-12, 1e12)\n",
        "            end\n",
        "        end\n",
        "        prev_H, prev_G = copy(H), copy(G)\n",
        "        return alpha\n",
        "    end\n",
        "end\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVjs_vuDtJRK",
        "outputId": "dd65099f-b866-46d7-8b7b-f7b78f2ce962"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "make_rule_spectral_H (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outros métodos"
      ],
      "metadata": {
        "id": "QJNdJmPXT6If"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6XDhgUiPVeZ"
      },
      "source": [
        "### NMF Inversa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIWLW8RCJhq5",
        "outputId": "bf58a556-9d57-475b-bfcf-fd1d6862fb14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nmf_inverse (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "function nmf_inverse(X, r; alpha=0.1, max_iter=max_iter_fixed, tol=tol_fixo)\n",
        "    m, n = size(X)\n",
        "    W = max.(rand(m, r), 1e-4)\n",
        "    H = max.(rand(r, n), 1e-4)\n",
        "    errors = Float64[]\n",
        "\n",
        "    t_start = time()\n",
        "    iters = 0\n",
        "\n",
        "    for iter = 1:max_iter\n",
        "        W_old = copy(W); H_old = copy(H)\n",
        "\n",
        "        A = H * H' + alpha*I(r)\n",
        "        W = X * H' * inv(A)\n",
        "        W .= max.(W, 0.0)\n",
        "        H .= H .* ((W' * X) ./ max.(W' * W * H, 1e-8))\n",
        "        H .= max.(H, 0.0)\n",
        "        push!(errors, norm(X - W*H))\n",
        "\n",
        "        if norm(W - W_old) / max(1, norm(W_old)) < tol &&\n",
        "          norm(H - H_old) / max(1, norm(H_old)) < tol\n",
        "            break\n",
        "        end\n",
        "    end\n",
        "\n",
        "    t_end = time()\n",
        "    total_time = t_end - t_start\n",
        "\n",
        "    return W, H, errors, total_time, iters\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALFN95BjxGKD"
      },
      "source": [
        "### Gradiente Projetado (atualização simultânea)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSTNfgrWggcG"
      },
      "source": [
        "$W^{t}$ e $H^{t}$ calculados simultaneamente. Espera-se terminar ambas $W^{t}$ e $H^{t}$ para calcular $W^{t+1}$ e $H^{t+1}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGYhrPKQxFi7",
        "outputId": "fec4ca20-2dd8-4f78-d5e9-7b790ac7d1ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nmf_pg_simultaneo (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "function nmf_pg_simultaneo(\n",
        "    X, r;\n",
        "    max_iter = max_iter_fixed,\n",
        "    tol = tol_fixo,\n",
        "    lambda = 0.0,\n",
        "    alpha_rule_W = (W,H,G,i,a)->a,\n",
        "    alpha_rule_H = (W,H,G,i,a)->a,\n",
        "    alphaW_init = 1e-3,\n",
        "    alphaH_init = 1e-3\n",
        ")\n",
        "    m, n = size(X)\n",
        "    W = max.(rand(m, r), 1e-4)\n",
        "    H = max.(rand(r, n), 1e-4)\n",
        "    errors = Float64[]\n",
        "    iters = 0\n",
        "\n",
        "    alphaW = alphaW_init\n",
        "    alphaH = alphaH_init\n",
        "\n",
        "    t_start = time()\n",
        "\n",
        "    for k = 1:max_iter\n",
        "        W_old = copy(W)\n",
        "        H_old = copy(H)\n",
        "\n",
        "        #task_W = Threads.@spawn begin\n",
        "            GW = W * (H * H') .- X * H' .+ lambda .* W\n",
        "            alphaW = alpha_rule_W(W, H, GW, k, alphaW)\n",
        "            W_new = max.(W .- alphaW .* GW, 0.0) #max.(W .- alphaW .* GW, 0.0), alphaW\n",
        "        #end\n",
        "\n",
        "        #task_H = Threads.@spawn begin\n",
        "            GH = (W' * W) * H .- W' * X .+ lambda .* H\n",
        "            alphaH = alpha_rule_H(W, H, GH, k, alphaH)\n",
        "            H_new = max.(H .- alphaH .* GH, 0.0) #max.(H .- alphaH .* GH, 0.0), alphaH\n",
        "        #end\n",
        "\n",
        "        #(W_new, alphaW) = fetch(task_W)\n",
        "        #(H_new, alphaH) = fetch(task_H)\n",
        "\n",
        "        W .= W_new\n",
        "        H .= H_new\n",
        "\n",
        "        push!(errors, norm(X - W * H))\n",
        "        iters = k\n",
        "\n",
        "        # Critério de parada\n",
        "        if norm(W - W_old) / max(1, norm(W_old)) < tol &&\n",
        "           norm(H - H_old) / max(1, norm(H_old)) < tol\n",
        "            break\n",
        "        end\n",
        "    end\n",
        "\n",
        "    total_time = time() - t_start\n",
        "    return W, H, errors, total_time, iters\n",
        "end\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvhkUW0snEW9"
      },
      "source": [
        "### Gradiente Projetado (atualização assíncrona)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVYxQjKxth0i"
      },
      "source": [
        "$W^{t}$ e $H^{t}$ calculados simultaneamente. Não se espera terminar ambas $W^{t}$ e $H^{t}$ para calcular $W^{t+1}$ e $H^{t+1}$. Nesse caso, pode ocorrer de várias iterações $W^t, ..., W^{t+1}$ usarem o mesmo $H^t$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBv71EkSnD1_",
        "outputId": "a15952dc-96b6-422e-a1e3-fc0b54e53c9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nmf_pg_async (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "function nmf_pg_async(\n",
        "    X, r;\n",
        "    max_iter = 5000,\n",
        "    tol = 1e-4,\n",
        "    lambda = 0.0,\n",
        "    alpha_rule_W = (W,H,G,i,a)->a,\n",
        "    alpha_rule_H = (W,H,G,i,a)->a,\n",
        "    alphaW_init = 1e-3,\n",
        "    alphaH_init = 1e-3\n",
        ")\n",
        "    m, n = size(X)\n",
        "    W = max.(rand(m, r), 1e-4)\n",
        "    H = max.(rand(r, n), 1e-4)\n",
        "    errors = Float64[]\n",
        "\n",
        "    lockW = ReentrantLock()\n",
        "    lockH = ReentrantLock()\n",
        "\n",
        "    stop_flag = Ref(false)\n",
        "    iter = Ref(0)\n",
        "\n",
        "    alphaW = alphaW_init\n",
        "    alphaH = alphaH_init\n",
        "\n",
        "    t_start = time()\n",
        "\n",
        "    # Atualiza W\n",
        "    taskW = Threads.@spawn begin\n",
        "        while !stop_flag[] && iter[] < max_iter\n",
        "            iter[] += 1\n",
        "\n",
        "            lock(lockH)\n",
        "            local H_local = copy(H)\n",
        "            unlock(lockH)\n",
        "\n",
        "            lock(lockW)\n",
        "            GW = W * H_local * H_local' .- X * H_local' .+ lambda .* W\n",
        "            alphaW = alpha_rule_W(W, H_local, GW, iter[], alphaW)\n",
        "            W_new = max.(W .- alphaW .* GW, 0.0)\n",
        "            ΔW = norm(W_new - W) / max(1, norm(W))\n",
        "            W .= W_new\n",
        "            unlock(lockW)\n",
        "\n",
        "            if ΔW < tol\n",
        "                stop_flag[] = true\n",
        "            end\n",
        "        end\n",
        "    end\n",
        "\n",
        "    # Atualiza H\n",
        "    taskH = Threads.@spawn begin\n",
        "        while !stop_flag[] && iter[] < max_iter\n",
        "            lock(lockW)\n",
        "            local W_local = copy(W)\n",
        "            unlock(lockW)\n",
        "\n",
        "            lock(lockH)\n",
        "            GH = (W_local' * W_local) * H .- W_local' * X .+ lambda .* H\n",
        "            alphaH = alpha_rule_H(W_local, H, GH, iter[], alphaH)\n",
        "            H_new = max.(H .- alphaH .* GH, 0.0)\n",
        "            ΔH = norm(H_new - H) / max(1, norm(H))\n",
        "            H .= H_new\n",
        "            unlock(lockH)\n",
        "\n",
        "            if ΔH < tol\n",
        "                stop_flag[] = true\n",
        "            end\n",
        "        end\n",
        "    end\n",
        "\n",
        "    # Monitora erro periodicamente\n",
        "    while !stop_flag[] && iter[] < max_iter\n",
        "        sleep(0.01)\n",
        "        lock(lockW); lock(lockH)\n",
        "        push!(errors, norm(X - W * H))\n",
        "        unlock(lockH); unlock(lockW)\n",
        "    end\n",
        "\n",
        "    total_time = time() - t_start\n",
        "    fetch(taskW); fetch(taskH)\n",
        "\n",
        "    return W, H, errors, total_time, iter[]\n",
        "end\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWz8--_jnqX_",
        "outputId": "5e0e197d-330a-48b8-9425-89623a78edd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threads disponíveis: 2\n",
            "Erro final = 3.410387719774216\n",
            "Tempo total = 2.524 s\n",
            "Iterações ≈ 1076\n"
          ]
        }
      ],
      "source": [
        "println(\"Threads disponíveis: \", Threads.nthreads())\n",
        "\n",
        "X = rand(10, 10)\n",
        "W, H, errors, t, iters = nmf_pg_async(X, 2;)\n",
        "println(\"Erro final = $(errors[end])\")\n",
        "println(\"Tempo total = $(round(t, digits=3)) s\")\n",
        "println(\"Iterações ≈ $iters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkTyUPHZJnLF"
      },
      "source": [
        "## NMF Multiplicativo (Lee & Seung)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1efOp22JqfG",
        "outputId": "0e7ec96f-83a8-4d43-b810-d5220b3f14f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nmf_multiplicative (generic function with 2 methods)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "function nmf_multiplicative(X, r, W_init, H_init; max_iter=max_iter_fixed, tol=tol_fixo)\n",
        "    m, n = size(X)\n",
        "    W = copy(W_init)\n",
        "    H = copy(H_init)\n",
        "    errors = Float64[]\n",
        "\n",
        "    t_start = time()\n",
        "    iters = 0\n",
        "\n",
        "    for iter = 1:max_iter\n",
        "        W_old = copy(W)\n",
        "        H_old = copy(H)\n",
        "\n",
        "        H .= H .* ((W' * X) ./ max.(W' * W * H, 1e-8))\n",
        "        H .= max.(H, 0.0)\n",
        "        W .= W .* ((X * H') ./ max.(W * (H * H'), 1e-8))\n",
        "        W .= max.(W, 0.0)\n",
        "\n",
        "        push!(errors, norm(X - W * H))\n",
        "        iters = iter\n",
        "\n",
        "        if norm(W - W_old) / max(1, norm(W_old)) < tol &&\n",
        "           norm(H - H_old) / max(1, norm(H_old)) < tol\n",
        "            break\n",
        "        end\n",
        "    end\n",
        "\n",
        "    t_end = time()\n",
        "    total_time = t_end - t_start\n",
        "    return W, H, errors, total_time, iters\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Minimização Alternada com Gradiente Projetado (Lin)"
      ],
      "metadata": {
        "id": "4EWN6PX1UbWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function line_search_lin!(W_old, W_new_cand, G, H, f_func;\n",
        "                          sigma = 0.01, beta = 0.1)\n",
        "    alpha = 1.0\n",
        "    f_old = f_func(W_old)\n",
        "\n",
        "    d = W_new_cand - W_old\n",
        "    expected_decrease = sum(G .* d)\n",
        "\n",
        "    iter_search = 0\n",
        "    max_search = 20\n",
        "\n",
        "    W_current = copy(W_new_cand)\n",
        "\n",
        "    while iter_search < max_search\n",
        "        # Condição de Armijo: f(W_new) - f(W_old) <= sigma * alpha * <grad, d>\n",
        "        if f_func(W_current) - f_old <= sigma * sum(G .* (W_current - W_old))\n",
        "            return W_current, alpha, nothing\n",
        "        end\n",
        "\n",
        "        # Contração do passo\n",
        "        alpha *= beta\n",
        "        W_current .= (1 - alpha) .* W_old .+ alpha .* W_new_cand\n",
        "        iter_search += 1\n",
        "    end\n",
        "\n",
        "    return W_old, 0.0, nothing # Se falhar, mantém o antigo\n",
        "end"
      ],
      "metadata": {
        "id": "MQI9znlnUax0",
        "outputId": "7d8abec7-3b24-4552-a050-37546d7ad291",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "line_search_lin! (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function projected_gradient_lin_W(X, H, W0; alpha_init = 1.0, tol = 1e-4, max_iter = 50)\n",
        "    W = copy(W0)\n",
        "    alpha = alpha_init\n",
        "    beta = 0.1\n",
        "    sigma = 0.01\n",
        "\n",
        "    HHt = H * H'\n",
        "    XHt = X * H'\n",
        "\n",
        "    inner_iter = 0\n",
        "    for iter = 1:max_iter\n",
        "        inner_iter = iter\n",
        "        G = W * HHt .- XHt\n",
        "        W_old = copy(W)\n",
        "\n",
        "        # algoritmo 4\n",
        "        W_cand = max.(W_old .- alpha .* G, 0.0)\n",
        "        d = W_cand .- W_old\n",
        "\n",
        "        suff_decr = (1-sigma)*sum(G .* d) + 0.5*tr(d * HHt * d') <= 0\n",
        "\n",
        "        if suff_decr\n",
        "            while suff_decr\n",
        "                W = copy(W_cand)\n",
        "                alpha /= beta\n",
        "                W_cand = max.(W_old .- alpha .* G, 0.0)\n",
        "                d = W_cand .- W_old\n",
        "                suff_decr = (1-sigma)*sum(G .* d) + 0.5*tr(d * HHt * d') <= 0\n",
        "                if alpha > 1e10 break end # Proteção numérica\n",
        "            end\n",
        "            alpha *= beta # Volta para o último alpha válido\n",
        "        else\n",
        "            while !suff_decr\n",
        "                alpha *= beta\n",
        "                W_cand = max.(W_old .- alpha .* G, 0.0)\n",
        "                d = W_cand .- W_old\n",
        "                suff_decr = (1-sigma)*sum(G .* d) + 0.5*tr(d * HHt * d') <= 0\n",
        "                if alpha < 1e-10 break end\n",
        "            end\n",
        "            W .= W_cand\n",
        "        end\n",
        "\n",
        "        if norm(W - W_old) / max(1.0, norm(W_old)) < tol\n",
        "            break\n",
        "        end\n",
        "    end\n",
        "    return W, inner_iter, alpha\n",
        "end"
      ],
      "metadata": {
        "id": "CgmgqXWz77lk",
        "outputId": "5be89659-090c-4dfc-dc9f-7c98d516d807",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "projected_gradient_lin_W (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function projected_gradient_lin_H(X, W, H0; alpha_init = 1.0, tol = 1e-4, max_iter = 50)\n",
        "    H = copy(H0)\n",
        "    alpha = alpha_init\n",
        "    beta = 0.1\n",
        "    sigma = 0.01\n",
        "\n",
        "    WtW = W' * W\n",
        "    WtX = W' * X\n",
        "\n",
        "    inner_iter = 0\n",
        "    for iter = 1:max_iter\n",
        "        inner_iter = iter\n",
        "        G = WtW * H .- WtX\n",
        "        H_old = copy(H)\n",
        "\n",
        "        H_cand = max.(H_old .- alpha .* G, 0.0)\n",
        "        d = H_cand .- H_old\n",
        "        # Condição de Armijo simplificada eq 4.3\n",
        "        suff_decr = (1-sigma)*sum(G .* d) + 0.5*tr(d' * WtW * d) <= 0\n",
        "\n",
        "        if suff_decr\n",
        "            while suff_decr\n",
        "                H = copy(H_cand)\n",
        "                alpha /= beta\n",
        "                H_cand = max.(H_old .- alpha .* G, 0.0)\n",
        "                d = H_cand .- H_old\n",
        "                suff_decr = (1-sigma)*sum(G .* d) + 0.5*tr(d' * WtW * d) <= 0\n",
        "                if alpha > 1e10 break end\n",
        "            end\n",
        "            alpha *= beta\n",
        "        else\n",
        "            while !suff_decr\n",
        "                alpha *= beta\n",
        "                H_cand = max.(H_old .- alpha .* G, 0.0)\n",
        "                d = H_cand .- H_old\n",
        "                suff_decr = (1-sigma)*sum(G .* d) + 0.5*tr(d' * WtW * d) <= 0\n",
        "                if alpha < 1e-10 break end\n",
        "            end\n",
        "            H .= H_cand\n",
        "        end\n",
        "\n",
        "        if norm(H - H_old) / max(1.0, norm(H_old)) < tol\n",
        "            break\n",
        "        end\n",
        "    end\n",
        "    return H, inner_iter, alpha\n",
        "end"
      ],
      "metadata": {
        "id": "0Ok_wRu78ERS",
        "outputId": "087dc0c7-561e-433a-acaf-fa1724ad1a6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "projected_gradient_lin_H (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function nmf_lin_algorithm(\n",
        "    X, r, W_init, H_init;\n",
        "    max_iter = 100,\n",
        "    tol = 1e-5,\n",
        "    sub_max_iter = 50,\n",
        "    sub_tol = 1e-4\n",
        ")\n",
        "    m, n = size(X)\n",
        "    # Inicialização conforme sugerido por Lin\n",
        "    W = copy(W_init)\n",
        "    H = copy(H_init)\n",
        "\n",
        "    errors = Float64[]\n",
        "    t_start = time()\n",
        "    total_sub_iters = 0\n",
        "\n",
        "    # Inicialização dos tamanhos de passo (alfa) para W e H\n",
        "    alpha_W = 1.0\n",
        "    alpha_H = 1.0\n",
        "\n",
        "    for iter = 1:max_iter\n",
        "        W_old = copy(W)\n",
        "        H_old = copy(H)\n",
        "\n",
        "        # --- Subproblema W ---\n",
        "        W, iter_W, alpha_W = projected_gradient_lin_W(X, H, W;\n",
        "            alpha_init = alpha_W, tol = sub_tol, max_iter = sub_max_iter)\n",
        "        total_sub_iters += iter_W\n",
        "\n",
        "        # --- Subproblema H ---\n",
        "        H, iter_H, alpha_H = projected_gradient_lin_H(X, W, H;\n",
        "            alpha_init = alpha_H, tol = sub_tol, max_iter = sub_max_iter)\n",
        "        total_sub_iters += iter_H\n",
        "\n",
        "        push!(errors, norm(X - W * H))\n",
        "\n",
        "        deltaW = norm(W - W_old) / max(1.0, norm(W_old))\n",
        "        deltaH = norm(H - H_old) / max(1.0, norm(H_old))\n",
        "\n",
        "        if deltaW < tol && deltaH < tol\n",
        "            break\n",
        "        end\n",
        "    end\n",
        "\n",
        "    return W, H, errors, time() - t_start, total_sub_iters\n",
        "end"
      ],
      "metadata": {
        "id": "oomf_Qt56Wpv",
        "outputId": "ad678ad8-091e-4dab-c85b-e87fc9e7f73d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nmf_lin_algorithm (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icLkSHEgRfgb"
      },
      "source": [
        "## Minimização Alternada com gradiente Projetado (espectral)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function line_search_segment!(\n",
        "    A_old, A_new, G, fixed_mat, f;\n",
        "    beta = 0.5,\n",
        "    sigma = 0.1,\n",
        "    theta_min = 1e-12,\n",
        "    monotone = true,\n",
        "    f_hist = nothing,\n",
        "    M_hist = 5 # número da memória\n",
        ")\n",
        "    # direcao\n",
        "    dW = A_new .- A_old\n",
        "    inner = sum(G .* dW)\n",
        "\n",
        "    # valor no ponto antigo\n",
        "    f_old = f(A_old, fixed_mat)\n",
        "\n",
        "    # se não-monotono, calcula máximo da janela\n",
        "    if monotone\n",
        "        f_ref = f_old\n",
        "    else\n",
        "        # inicializa histórico se necessário\n",
        "        if f_hist === nothing || isempty(f_hist)\n",
        "            f_hist = [f_old]\n",
        "        end\n",
        "\n",
        "        # referencia = maior valor recente\n",
        "        f_ref = maximum(f_hist)\n",
        "    end\n",
        "\n",
        "    # começa com passo cheio\n",
        "    theta = 1.0\n",
        "    f_new = f(A_new, fixed_mat)\n",
        "\n",
        "    # condicao geral\n",
        "    while f_new > f_ref - sigma * theta * inner\n",
        "        theta *= beta\n",
        "        if theta < theta_min\n",
        "            break\n",
        "        end\n",
        "        A_new .= A_old .+ theta .* dW\n",
        "        f_new = f(A_new, fixed_mat)\n",
        "    end\n",
        "\n",
        "    # se for não-monotono, atualiza histórico\n",
        "    if !monotone\n",
        "        push!(f_hist, f_new)\n",
        "        if length(f_hist) > M_hist\n",
        "            popfirst!(f_hist)  # mantém último M_hist valores\n",
        "        end\n",
        "    end\n",
        "\n",
        "    return A_new, theta, f_hist\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGek0SHeK8od",
        "outputId": "8fdb2dde-6cf1-4aab-dcff-aaa13a4496ce"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "line_search_segment! (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function projected_gradient_W(X, H, W0;\n",
        "    alpha_init = 1e-3,\n",
        "    lambda = 0.0,\n",
        "    tol = tol_fixo_sub,\n",
        "    max_iter = max_iter_fixed,\n",
        "    monotone = true,\n",
        "    alpha_rule_W = (W, H, G, iter, alpha_prev) -> alpha_prev\n",
        ")\n",
        "    W = copy(W0)\n",
        "    alpha = alpha_init\n",
        "    f_W(Wt,Ht) = 0.5 * norm(X - Wt*Ht)^2 + (lambda/2)*norm(Wt)^2\n",
        "    f_hist_W = nothing\n",
        "\n",
        "    for iter = 1:max_iter\n",
        "        W_old = copy(W)\n",
        "\n",
        "        GW = W * (H * H') .- X * H' .+ lambda .* W\n",
        "        alpha = alpha_rule_W(W, H, GW, iter, alpha)\n",
        "        W .= max.(W .- alpha .* GW, 0.0)\n",
        "\n",
        "        W_new, theta, new_f_hist_W = line_search_segment!(\n",
        "            W_old, W, GW, H, f_W;\n",
        "            monotone = monotone,\n",
        "            f_hist = f_hist_W,\n",
        "            M_hist = 5\n",
        "        )\n",
        "        W .= W_new\n",
        "        f_hist_W = new_f_hist_W\n",
        "\n",
        "        if norm(W - W_old) / max(1.0, norm(W_old)) < tol\n",
        "            return W, iter\n",
        "        end\n",
        "    end\n",
        "\n",
        "    return W, max_iter\n",
        "end\n",
        "\n",
        "function projected_gradient_H(X, W, H0;\n",
        "    alpha_init = 1e-3,\n",
        "    lambda = 0.0,\n",
        "    tol = tol_fixo_sub,\n",
        "    max_iter = max_iter_fixed,\n",
        "    monotone = true,\n",
        "    alpha_rule_H = (W, H, G, iter, alpha_prev) -> alpha_prev\n",
        ")\n",
        "    H = copy(H0)\n",
        "    alpha = alpha_init\n",
        "    f_H(Ht, Wt) = 0.5 * norm(X - Wt * Ht)^2 + (lambda/2)*norm(Ht)^2\n",
        "    f_hist_H = nothing\n",
        "\n",
        "    for iter = 1:max_iter\n",
        "        H_old = copy(H)\n",
        "\n",
        "        GH = (W' * W) * H .- W' * X .+ lambda .* H\n",
        "        alpha = alpha_rule_H(W, H, GH, iter, alpha)\n",
        "        H .= max.(H .- alpha .* GH, 0.0)\n",
        "\n",
        "        H_new, theta, new_f_hist_H = line_search_segment!(\n",
        "            H_old, H, GH, W, f_H;\n",
        "            monotone = monotone,\n",
        "            f_hist = f_hist_H,\n",
        "            M_hist = 5\n",
        "        )\n",
        "        H .= H_new\n",
        "        f_hist_H = new_f_hist_H\n",
        "\n",
        "        if norm(H - H_old) / max(1.0, norm(H_old)) < tol\n",
        "            return H, iter\n",
        "        end\n",
        "    end\n",
        "\n",
        "    return H, max_iter\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-NQ_Hm5fOKa",
        "outputId": "c13bab11-4291-4842-f80f-9888a329a0f5"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "projected_gradient_H (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function nmf_gradient_projected(\n",
        "    X, r, W_init, H_init;\n",
        "    max_iter = max_iter_fixed,\n",
        "    tol = tol_fixo,\n",
        "    alpha_init = 1e-3,\n",
        "    lambda = 0.0,\n",
        "    sub_max_iter = max_iter_fixed,\n",
        "    sub_tol = tol_fixo_sub,\n",
        "    monotone = true,\n",
        "    alpha_rule_W = (W, H, G, i, a) -> a,\n",
        "    alpha_rule_H = (W, H, G, i, a) -> a\n",
        ")\n",
        "    m, n = size(X)\n",
        "\n",
        "    W = copy(W_init)\n",
        "    H = copy(H_init)\n",
        "    errors = Float64[]\n",
        "\n",
        "    t_start = time()\n",
        "    total_sub_iters = 0\n",
        "\n",
        "    for iter = 1:max_iter\n",
        "        W_old = copy(W)\n",
        "        H_old = copy(H)\n",
        "\n",
        "        # --- Atualização de W ---\n",
        "        W, iter_W = projected_gradient_W(X, H, W;\n",
        "            alpha_init = alpha_init,\n",
        "            lambda = lambda,\n",
        "            tol = sub_tol,\n",
        "            max_iter = sub_max_iter,\n",
        "            monotone = monotone,\n",
        "            alpha_rule_W = alpha_rule_W\n",
        "        )\n",
        "        total_sub_iters += iter_W\n",
        "\n",
        "        # --- Atualização de H ---\n",
        "        H, iter_H = projected_gradient_H(X, W, H;\n",
        "            alpha_init = alpha_init,\n",
        "            lambda = lambda,\n",
        "            tol = sub_tol,\n",
        "            max_iter = sub_max_iter,\n",
        "            monotone = monotone,\n",
        "            alpha_rule_H = alpha_rule_H\n",
        "        )\n",
        "        total_sub_iters += iter_H\n",
        "\n",
        "        push!(errors, norm(X - W * H))\n",
        "\n",
        "        deltaW = norm(W - W_old) / max(1.0, norm(W_old))\n",
        "        deltaH = norm(H - H_old) / max(1.0, norm(H_old))\n",
        "        if deltaW < tol && deltaH < tol\n",
        "            break\n",
        "        end\n",
        "    end\n",
        "\n",
        "    total_time = time() - t_start\n",
        "    return W, H, errors, total_time, total_sub_iters\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz1scpIXydon",
        "outputId": "2232f2e1-7d50-4c9d-db7f-b792a5593de3"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nmf_gradient_projected (generic function with 2 methods)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "aLTlTij0SpP3"
      },
      "outputs": [],
      "source": [
        "#function nmf_gradient_projected_(\n",
        "#  X, r;\n",
        "#  max_iter=max_iter_fixed,\n",
        "#  tol=tol_fixo,\n",
        "#  alpha_init=1e-3,\n",
        "#  lambda=0.0,\n",
        "#  alpha_rule_W = (W, H, GW, iter, alpha_prev) -> alpha_prev,\n",
        "#  alpha_rule_H = (W, H, GH, iter, alpha_prev) -> alpha_prev)\n",
        "#\n",
        "#    m, n = size(X)\n",
        "#    W = max.(rand(m, r), 1e-4)\n",
        "#    H = max.(rand(r, n), 1e-4)\n",
        "#    errors = Float64[]\n",
        "#\n",
        "#    alpha_W, alpha_H = alpha_init, alpha_init\n",
        "#\n",
        "#    t_start = time()\n",
        "#    iters = 0\n",
        "#\n",
        "#    for iter = 1:max_iter\n",
        "#        W_old = copy(W); H_old = copy(H)\n",
        "#\n",
        "#        # Atualização de W\n",
        "#        GW = W * (H * H') .- X * H' .+ lambda .* W\n",
        "#        alpha_W = alpha_rule_W(W, H, GW, iter, alpha_W)\n",
        "#        W .= max.(W .- alpha_W .* GW, 0.0)\n",
        "#\n",
        "#        # Atualização de H\n",
        "#        GH = (W' * W) * H .- W' * X .+ lambda .* H\n",
        "#        alpha_H = alpha_rule_H(W, H, GH, iter, alpha_H)\n",
        "#        H .= max.(H .- alpha_H .* GH, 0.0)\n",
        "#\n",
        "#        push!(errors, norm(X - W*H))\n",
        "#        iters = iter\n",
        "#\n",
        "#        if norm(W - W_old) / max(1, norm(W_old)) < tol &&\n",
        "#           norm(H - H_old) / max(1, norm(H_old)) < tol\n",
        "#            break\n",
        "#        end\n",
        "#    end\n",
        "#\n",
        "#    t_end = time()\n",
        "#    total_time = t_end - t_start\n",
        "#    return W, H, errors, total_time, iters\n",
        "#end\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6uDFFYZSofZ"
      },
      "source": [
        "## Testes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEvZ4HjSGCwy",
        "outputId": "ee42009d-758e-4b53-c2de-52ba20c8ad6d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dict{Symbol, Function} with 4 entries:\n",
              "  :lin                                       => nmf_lin_algorithm\n",
              "  :gradiente_projetado_spectral_monotone     => #232\n",
              "  :multiplicativo                            => nmf_multiplicative\n",
              "  :gradiente_projetado_spectral_non_monotone => #230"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "dims = [100, 1000]\n",
        "r_values = [5, 10, 20]\n",
        "types = [:equal, :ill_conditioned]\n",
        "\n",
        "#dims = [1000]\n",
        "#r_values = [5, 100, 500]\n",
        "#types = [:equal, :ill_conditioned]\n",
        "\n",
        "models = Dict{Symbol, Function}(\n",
        "    :multiplicativo => nmf_multiplicative,\n",
        "    :lin => nmf_lin_algorithm,\n",
        "\n",
        "    :gradiente_projetado_spectral_non_monotone => (X, r, W, H; kwargs...) -> nmf_gradient_projected(\n",
        "        X, r, W, H;\n",
        "        alpha_rule_W = make_rule_spectral_W(),\n",
        "        alpha_rule_H = make_rule_spectral_H(),\n",
        "        monotone = false,\n",
        "        kwargs...\n",
        "    ),\n",
        "\n",
        "    :gradiente_projetado_spectral_monotone => (X, r, W, H; kwargs...) -> nmf_gradient_projected(\n",
        "        X, r, W, H;\n",
        "        alpha_rule_W = make_rule_spectral_W(),\n",
        "        alpha_rule_H = make_rule_spectral_H(),\n",
        "        monotone = true,\n",
        "        kwargs...\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrizes aleatórias $X, W, H$"
      ],
      "metadata": {
        "id": "N0pA3twwII4a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zZpTP2rGWbj",
        "outputId": "1a2ea7fe-aa5a-4023-e74f-b46a967e54b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Dimension = 100 | rank = 5 | type = equal ===\n",
            "lin → Erro final: 5.5441209676114465 | Iterações: 1761 | Tempo: 0.3151s\n",
            "gradiente_projetado_spectral_monotone → Erro final: 5.544120655391608 | Iterações: 14 | Tempo: 2.3866s\n",
            "multiplicativo → Erro final: 5.544119778035748 | Iterações: 4 | Tempo: 0.0004s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 5.544119688469664 | Iterações: 14 | Tempo: 0.0019s\n",
            "\n",
            "=== Dimension = 100 | rank = 5 | type = ill_conditioned ===\n",
            "lin → Erro final: 0.7722639525369286 | Iterações: 2381 | Tempo: 0.2373s\n",
            "gradiente_projetado_spectral_monotone → Erro final: 0.7722524105124817 | Iterações: 17 | Tempo: 0.0045s\n",
            "multiplicativo → Erro final: 0.7721175261222393 | Iterações: 223 | Tempo: 0.0242s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 0.7721060434725183 | Iterações: 14 | Tempo: 0.003s\n",
            "\n",
            "=== Dimension = 100 | rank = 10 | type = equal ===\n",
            "lin → Erro final: 5.1191809883222 | Iterações: 2845 | Tempo: 0.3595s\n",
            "gradiente_projetado_spectral_monotone → Erro final: 5.118979828943644 | Iterações: 105 | Tempo: 0.0221s\n",
            "multiplicativo → Erro final: 5.117241758063353 | Iterações: 654 | Tempo: 0.0787s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 5.116054729327271 | Iterações: 329 | Tempo: 0.0598s\n",
            "\n",
            "=== Dimension = 100 | rank = 10 | type = ill_conditioned ===\n",
            "lin → Erro final: 0.6287555107579281 | Iterações: 1537 | Tempo: 0.1886s\n",
            "gradiente_projetado_spectral_monotone → Erro final: 0.6287367209751413 | Iterações: 22 | Tempo: 0.0047s\n",
            "multiplicativo → Erro final: 0.6284254830346471 | Iterações: 352 | Tempo: 0.0449s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 0.6284140068676574 | Iterações: 21 | Tempo: 0.0031s\n",
            "\n",
            "=== Dimension = 100 | rank = 20 | type = equal ===\n",
            "lin → Erro final: 4.4661402509084 | Iterações: 2561 | Tempo: 0.4339s\n",
            "gradiente_projetado_spectral_monotone → Erro final: 4.465977455752817 | Iterações: 65 | Tempo: 0.0187s\n",
            "multiplicativo → Erro final: 4.464582232314459 | Iterações: 501 | Tempo: 0.0971s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 4.464462620911977 | Iterações: 25 | Tempo: 0.0085s\n",
            "\n",
            "=== Dimension = 100 | rank = 20 | type = ill_conditioned ===\n",
            "lin → Erro final: 0.4716372849409785 | Iterações: 2509 | Tempo: 0.4251s\n",
            "gradiente_projetado_spectral_monotone → Erro final: 0.47161633741875864 | Iterações: 33 | Tempo: 0.0096s\n",
            "multiplicativo → Erro final: 0.47103685937323597 | Iterações: 539 | Tempo: 0.0955s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 0.4709981635249332 | Iterações: 24 | Tempo: 0.0094s\n",
            "\n",
            "=== Dimension = 1000 | rank = 5 | type = equal ===\n",
            "lin → Erro final: 18.89977765776604 | Iterações: 2044 | Tempo: 15.5832s\n",
            "gradiente_projetado_spectral_monotone → Erro final: 18.899759766883317 | Iterações: 56 | Tempo: 1.3531s\n",
            "multiplicativo → Erro final: 18.899750253596753 | Iterações: 9 | Tempo: 0.0936s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 18.899742513210832 | Iterações: 15 | Tempo: 0.2429s\n",
            "\n",
            "=== Dimension = 1000 | rank = 5 | type = ill_conditioned ===\n",
            "lin → Erro final: 3.1097342539907213 | Iterações: 974 | Tempo: 7.8834s\n",
            "gradiente_projetado_spectral_monotone → Erro final: 3.109732183154931 | Iterações: 14 | Tempo: 0.3057s\n",
            "multiplicativo → Erro final: 3.1097297518484575 | Iterações: 17 | Tempo: 0.2102s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 3.109729344250648 | Iterações: 14 | Tempo: 0.2751s\n",
            "\n",
            "=== Dimension = 1000 | rank = 10 | type = equal ===\n",
            "lin → Erro final: 18.715228585617616 | Iterações: 2767 | Tempo: 22.688s\n",
            "gradiente_projetado_spectral_monotone → Erro final: 18.71484050843437 | Iterações: 117 | Tempo: 3.0646s\n",
            "multiplicativo → Erro final: 18.714108509687975 | Iterações: 371 | Tempo: 4.2738s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 18.71407595254623 | Iterações: 28 | Tempo: 0.7864s\n",
            "\n",
            "=== Dimension = 1000 | rank = 10 | type = ill_conditioned ===\n",
            "lin → Erro final: 3.068717332605453 | Iterações: 1390 | Tempo: 12.2106s\n",
            "gradiente_projetado_spectral_monotone → Erro final: 3.0685643234071183 | Iterações: 65 | Tempo: 1.562s\n",
            "multiplicativo → Erro final: 3.067984642187398 | Iterações: 760 | Tempo: 9.4557s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 3.0679640405802004 | Iterações: 27 | Tempo: 0.4652s\n",
            "\n",
            "=== Dimension = 1000 | rank = 20 | type = equal ===\n",
            "lin → Erro final: 18.424882850580907 | Iterações: 1903 | Tempo: 22.4166s\n",
            "gradiente_projetado_spectral_monotone → Erro final: 18.42481769789083 | Iterações: 26 | Tempo: 0.5658s\n",
            "multiplicativo → Erro final: 18.424340305699666 | Iterações: 226 | Tempo: 3.0514s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 18.424156653956672 | Iterações: 78 | Tempo: 2.2835s\n",
            "\n",
            "=== Dimension = 1000 | rank = 20 | type = ill_conditioned ===\n",
            "lin → Erro final: 2.998238587675988 | Iterações: 2030 | Tempo: 24.9647s\n",
            "gradiente_projetado_spectral_monotone → Erro final: 2.9981817017482033 | Iterações: 25 | Tempo: 1.2108s\n",
            "multiplicativo → Erro final: 2.99716148524108 | Iterações: 792 | Tempo: 13.3167s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 2.9971014861067444 | Iterações: 24 | Tempo: 1.034s\n"
          ]
        }
      ],
      "source": [
        "for n in dims\n",
        "    for r in r_values\n",
        "        if r > n\n",
        "            continue\n",
        "        end\n",
        "\n",
        "        for t in types\n",
        "            println(\"\\n=== Dimension = $n | rank = $r | type = $t ===\")\n",
        "            X = generate_matrix(n,n, type=t)\n",
        "            m,n = size(X)\n",
        "\n",
        "            W = max.(rand(m, r), 1e-4)\n",
        "            H = max.(rand(r, n), 1e-4)\n",
        "\n",
        "            for (name, model) in models\n",
        "                W, H, err, total_time, iters = model(X, r, W, H)\n",
        "\n",
        "                erro_final = isempty(err) ? NaN : err[end]\n",
        "                tempo = round(total_time, digits=4)\n",
        "\n",
        "                println(\"$(string(name)) → Erro final: $erro_final | Iterações: $iters | Tempo: $(tempo)s\")\n",
        "            end\n",
        "        end\n",
        "    end\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Teste exato $X = WH$"
      ],
      "metadata": {
        "id": "7p8B2s6rLtxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dims = [10, 100, 1000]\n",
        "r_values = [10]\n",
        "types = [:equal]\n",
        "\n",
        "for n in dims\n",
        "    for r in r_values\n",
        "        if r > n\n",
        "            continue\n",
        "        end\n",
        "\n",
        "        for t in types\n",
        "            println(\"\\n=== Dimension = $n | rank = $r | type = $t ===\")\n",
        "            X, W_true, H_true = generate_X_WH(n, n, r; type=t)\n",
        "\n",
        "            for (name, model) in models\n",
        "                W, H, err, total_time, iters = model(X, r)\n",
        "\n",
        "                erro_final = isempty(err) ? NaN : err[end]\n",
        "                tempo = round(total_time, digits=4)\n",
        "\n",
        "                err_WH = norm(X - W * H) / norm(X)\n",
        "                err_W  = norm(W - W_true) / norm(W_true)\n",
        "                err_H  = norm(H - H_true) / norm(H_true)\n",
        "                println(\"$(string(name)) → Erro(X): $(round(err_WH,digits=6)) | Erro(W): $(round(err_W,digits=6)) | Erro(H): $(round(err_H,digits=6)) | Iterações: $iters | Tempo: $(tempo)s\")\n",
        "            end\n",
        "        end\n",
        "    end\n",
        "end"
      ],
      "metadata": {
        "id": "gSiYKxSIL_VN",
        "outputId": "62354652-bca4-4e52-a6a1-bacddd61f6c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Dimension = 10 | rank = 10 | type = equal ===\n",
            "gradiente_projetado_spectral_monotone → Erro(X): 0.000229 | Erro(W): 0.822766 | Erro(H): 2.063396 | Iterações: 6372 | Tempo: 0.1009s\n",
            "multiplicativo → Erro(X): 0.002688 | Erro(W): 1.551131 | Erro(H): 0.77782 | Iterações: 364 | Tempo: 0.0056s\n",
            "gradiente_projetado_spectral_non_monotone → Erro(X): 0.000149 | Erro(W): 0.745433 | Erro(H): 1.746496 | Iterações: 7777 | Tempo: 0.1012s\n",
            "\n",
            "=== Dimension = 100 | rank = 10 | type = equal ===\n",
            "gradiente_projetado_spectral_monotone → Erro(X): 0.038314 | Erro(W): 0.902373 | Erro(H): 8.142552 | Iterações: 3172 | Tempo: 0.7288s\n",
            "multiplicativo → Erro(X): 0.012938 | Erro(W): 5.852569 | Erro(H): 0.907073 | Iterações: 1297 | Tempo: 0.2102s\n",
            "gradiente_projetado_spectral_non_monotone → Erro(X): 0.057268 | Erro(W): 0.899164 | Erro(H): 8.15689 | Iterações: 1170 | Tempo: 0.3124s\n",
            "\n",
            "=== Dimension = 1000 | rank = 10 | type = equal ===\n",
            "gradiente_projetado_spectral_monotone → Erro(X): 0.078045 | Erro(W): 0.968311 | Erro(H): 28.616065 | Iterações: 2558 | Tempo: 68.3501s\n",
            "multiplicativo → Erro(X): 0.013576 | Erro(W): 19.804687 | Erro(H): 0.970246 | Iterações: 1937 | Tempo: 25.6221s\n",
            "gradiente_projetado_spectral_non_monotone → Erro(X): 0.059816 | Erro(W): 0.967848 | Erro(H): 25.984455 | Iterações: 3548 | Tempo: 87.2986s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "sYMC_nUdJBSC",
        "outputId": "7712d9f8-b9c7-4e83-f438-3d6f5b04a1d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===============================\n",
            "=== Dimensão = 200 | rank = 10 | tipo = uniform ===\n",
            "===============================\n",
            "1, 2, 3, 4, 5, 6, 7, 8, 9, 10, \n",
            "\n",
            "=== Estatísticas do erro final (n = 200) ===\n",
            "gradiente_projetado_spectral_monotone → Média = 4.602434 | Std = 0.115082\n",
            "multiplicativo                      → Média = 4.552643 | Std = 0.120639\n",
            "gradiente_projetado_spectral_non_monotone → Média = 4.584612 | Std = 0.120370\n",
            "\n",
            "=== Estatísticas de tempo (n = 200) ===\n",
            "gradiente_projetado_spectral_monotone → Média = 0.230619s | Std = 0.073465s\n",
            "multiplicativo                      → Média = 0.984121s | Std = 0.095488s\n",
            "gradiente_projetado_spectral_non_monotone → Média = 0.308453s | Std = 0.130616s\n",
            "\n",
            "=== Estatísticas do número de iterações (n = 200) ===\n",
            "gradiente_projetado_spectral_monotone → Média = 7.10 | Std = 3.35\n",
            "multiplicativo                      → Média = 2446.40 | Std = 296.92\n",
            "gradiente_projetado_spectral_non_monotone → Média = 11.80 | Std = 6.25\n"
          ]
        }
      ],
      "source": [
        "num_trials = 10\n",
        "dims = [200]\n",
        "r = 10\n",
        "type = :uniform\n",
        "\n",
        "for n in dims\n",
        "    println(\"\\n===============================\")\n",
        "    println(\"=== Dimensão = $n | rank = $r | tipo = $type ===\")\n",
        "    println(\"===============================\")\n",
        "\n",
        "    # inicializa dicionários\n",
        "    errors = Dict(model => [] for model in keys(models))\n",
        "    times  = Dict(model => Float64[] for model in keys(models))\n",
        "    iters  = Dict(model => Int[] for model in keys(models))\n",
        "\n",
        "    # ----------------------------------------------------------\n",
        "    # Loop principal\n",
        "    # ----------------------------------------------------------\n",
        "    for trial in 1:num_trials\n",
        "        print(\"$trial, \")\n",
        "        X = generate_matrix(n, n, type=type)\n",
        "\n",
        "        for (name, model) in models\n",
        "            t_start = time()\n",
        "            _, _, err = model(X, r)\n",
        "            t_end = time()\n",
        "\n",
        "            push!(errors[name], err)\n",
        "            push!(times[name], t_end - t_start)\n",
        "            push!(iters[name], length(err))\n",
        "        end\n",
        "    end\n",
        "    println(\"\\n\")\n",
        "\n",
        "    # ----------------------------------------------------------\n",
        "    # Estatísticas de erro final\n",
        "    # ----------------------------------------------------------\n",
        "    println(\"=== Estatísticas do erro final (n = $n) ===\")\n",
        "    for name in keys(models)\n",
        "        final_errs = [isempty(e) ? NaN : e[end] for e in errors[name]]\n",
        "        media = mean(skipmissing(final_errs))\n",
        "        desvio = std(skipmissing(final_errs))\n",
        "        @printf(\"%-35s → Média = %.6f | Std = %.6f\\n\", string(name), media, desvio)\n",
        "    end\n",
        "\n",
        "    # ----------------------------------------------------------\n",
        "    # Estatísticas de tempo\n",
        "    # ----------------------------------------------------------\n",
        "    println(\"\\n=== Estatísticas de tempo (n = $n) ===\")\n",
        "    for name in keys(models)\n",
        "        media = mean(times[name])\n",
        "        desvio = std(times[name])\n",
        "        @printf(\"%-35s → Média = %.6fs | Std = %.6fs\\n\", string(name), media, desvio)\n",
        "    end\n",
        "\n",
        "    # ----------------------------------------------------------\n",
        "    # Estatísticas de iterações\n",
        "    # ----------------------------------------------------------\n",
        "    println(\"\\n=== Estatísticas do número de iterações (n = $n) ===\")\n",
        "    for name in keys(models)\n",
        "        media = mean(iters[name])\n",
        "        desvio = std(iters[name])\n",
        "        @printf(\"%-35s → Média = %.2f | Std = %.2f\\n\", string(name), media, desvio)\n",
        "    end\n",
        "end\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEtJNu32HDTx"
      },
      "source": [
        "# NMF package"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## https://nimfa.biolab.si/nimfa.datasets.html"
      ],
      "metadata": {
        "id": "VAKuExZ3sqJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRHpk7ZNHCr2",
        "outputId": "fce2e77f-cab5-4adc-82d3-d0a34b716598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m\u001b[1m     Cloning\u001b[22m\u001b[39m git-repo `https://github.com/JuliaStats/NMF.jl`\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaStats/NMF.jl`\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m NonNegLeastSquares ─ v0.4.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m RandomizedLinAlg ─── v0.1.0\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.11/Project.toml`\n",
            "  \u001b[90m[6ef6ca0d] \u001b[39m\u001b[92m+ NMF v1.0.3 `https://github.com/JuliaStats/NMF.jl#master`\u001b[39m\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.11/Manifest.toml`\n",
            "  \u001b[90m[6ef6ca0d] \u001b[39m\u001b[92m+ NMF v1.0.3 `https://github.com/JuliaStats/NMF.jl#master`\u001b[39m\n",
            "  \u001b[90m[b7351bd1] \u001b[39m\u001b[92m+ NonNegLeastSquares v0.4.1\u001b[39m\n",
            "  \u001b[90m[0448d7d9] \u001b[39m\u001b[92m+ RandomizedLinAlg v0.1.0\u001b[39m\n",
            "\u001b[92m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "   4984.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mNonNegLeastSquares\u001b[39m\n",
            "   3881.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mRandomizedLinAlg\u001b[39m\n",
            "  42869.2 ms\u001b[32m  ✓ \u001b[39mNMF\n",
            "  3 dependencies successfully precompiled in 55 seconds. 490 already precompiled.\n"
          ]
        }
      ],
      "source": [
        "using Pkg\n",
        "Pkg.add(url=\"https://github.com/JuliaStats/NMF.jl\")\n",
        "using NMF\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "http://mtm.ufsc.br/~douglas/2019.1/MTM5813/matlab/"
      ],
      "metadata": {
        "id": "w6ugqYQseZlO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "41lLifSQeaFR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_6XDhgUiPVeZ",
        "KkTyUPHZJnLF",
        "ALFN95BjxGKD",
        "vvhkUW0snEW9"
      ],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Julia",
      "name": "julia"
    },
    "language_info": {
      "name": "julia"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}