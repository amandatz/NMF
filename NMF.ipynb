{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amandatz/NMF/blob/main/NMF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NMF"
      ],
      "metadata": {
        "id": "d8uJ7PpJCz5v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ep9DvChlqxf"
      },
      "outputs": [],
      "source": [
        "using LinearAlgebra, Random, Plots, Statistics, Printf\n",
        "using Base.Threads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj8t-IqYmNU0",
        "outputId": "6d882b3b-efb9-41d5-c6f1-fcbe27ec4e62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TaskLocalRNG()"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "using Random\n",
        "Random.seed!(123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ETqjQrZJeOM"
      },
      "source": [
        "## Auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRt6JeaJVLYc",
        "outputId": "693a6b6e-4ccc-43ef-bb74-8eba22c89e04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0000000000000002e-6"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "max_iter_fixed = 100000\n",
        "tol_fixo = 1e-4\n",
        "tol_fixo_sub = tol_fixo*0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjgoj2_iJf-N",
        "outputId": "cc3a14f1-ada2-4c25-aaca-45a114e55b87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "generate_X_WH (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "function generate_matrix(m, n; type=:uniform)\n",
        "    Q1 = qr(randn(m, m)).Q\n",
        "    Q2 = qr(randn(n, n)).Q\n",
        "    d = zeros(min(m, n))\n",
        "    kappa = 1e8\n",
        "\n",
        "    if type == :uniform\n",
        "        d .= rand(length(d))\n",
        "\n",
        "    elseif type == :decaying\n",
        "        d .= LinRange(1.0, 0.1, length(d))\n",
        "\n",
        "    elseif type == :equal\n",
        "        d .= ones(length(d))\n",
        "\n",
        "    elseif type == :ill_conditioned\n",
        "        d .= [1 / kappa^((i - 1) / (length(d) - 1)) for i in 1:length(d)]\n",
        "\n",
        "    else\n",
        "        error(\"Tipo inválido\")\n",
        "    end\n",
        "\n",
        "    X = abs.(Q1[:, 1:length(d)] * Diagonal(d) * Q2'[1:length(d), :])\n",
        "    return X\n",
        "end\n",
        "\n",
        "function generate_X_WH(m, n, r; type=:uniform)\n",
        "    W = generate_matrix(m, r; type=type)\n",
        "    H = generate_matrix(r, n; type=type)\n",
        "    X = W * H\n",
        "    return X, W, H\n",
        "end\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function lipschitz_step(A; eps = 1e-8)\n",
        "    L = opnorm(A) + eps\n",
        "    return 1 / L\n",
        "end\n",
        "\n",
        "function rule_lipschitz_W(W, H, GW, iter, alpha_prev)\n",
        "    return lipschitz_step(H * H')\n",
        "end\n",
        "\n",
        "function rule_lipschitz_H(W, H, GH, iter, alpha_prev)\n",
        "    return lipschitz_step(W' * W)\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chNpyuu1FGT5",
        "outputId": "ef43e48a-0a14-418e-a5b2-dbad7945065f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rule_lipschitz_H (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Armijo"
      ],
      "metadata": {
        "id": "s_lIerdh7FOC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Busca Linear de Armijo com Backtracking"
      ],
      "metadata": {
        "id": "_Ve9sIPE7C7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function armijo_step(\n",
        "    F_func, X, G;\n",
        "    alpha_init = 1e-3, beta = 0.5, c = 1e-4,\n",
        "    max_iter = 20, proj = identity\n",
        ")\n",
        "    alpha = alpha_init\n",
        "    F = F_func(X)\n",
        "    normG2 = norm(G)^2\n",
        "    for k = 1:max_iter\n",
        "        X_new = proj(X .- alpha .* G)\n",
        "        F_new = F_func(X_new)\n",
        "        if F_new <= F - c * alpha * normG2\n",
        "            return alpha\n",
        "        end\n",
        "        alpha *= beta\n",
        "    end\n",
        "    return alpha\n",
        "end\n",
        "\n",
        "function rule_armijo_W(W, H, GW, iter, alpha_prev)\n",
        "    F_func = Wt -> 0.5 * norm(X - Wt * H)^2\n",
        "    return armijo_step(F_func, W, GW; alpha_init=alpha_prev, proj=x->max.(x,0.0))\n",
        "end\n",
        "\n",
        "function rule_armijo_H(W, H, GH, iter, alpha_prev)\n",
        "    F_func = Ht -> 0.5 * norm(X - W * Ht)^2\n",
        "    return armijo_step(F_func, H, GH; alpha_init=alpha_prev, proj=x->max.(x,0.0))\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NCRmwDKFOYz",
        "outputId": "020226fd-e710-4c3e-98fb-180a9896b00b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rule_armijo_H (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function rule_hybrid_H(W, H, GH, iter, alpha_prev)\n",
        "    alpha_lip = 1 / (opnorm(W' * W) + 1e-8)\n",
        "    F_func = Ht -> 0.5 * norm(X - W * Ht)^2\n",
        "    return armijo_step(F_func, H, GH;\n",
        "        alpha_init = alpha_lip,\n",
        "        proj = x -> max.(x, 0.0)\n",
        "    )\n",
        "end\n",
        "\n",
        "function rule_hybrid_W(W, H, GW, iter, alpha_prev)\n",
        "    alpha_lip = 1 / (opnorm(H * H') + 1e-8)\n",
        "    F_func = Wt -> 0.5 * norm(Wt * H - X)^2\n",
        "    return armijo_step(F_func, W, GW;\n",
        "        alpha_init = alpha_lip,\n",
        "        proj = x -> max.(x, 0.0)\n",
        "    )\n",
        "end\n",
        "\n",
        "function rule_hybrid_H(W, H, GH, iter, alpha_prev)\n",
        "    alpha_lip = 1 / (opnorm(W' * W) + 1e-8)\n",
        "    F_func = Ht -> 0.5 * norm(W * Ht - X)^2\n",
        "    return armijo_step(F_func, H, GH;\n",
        "        alpha_init = alpha_lip,\n",
        "        proj = x -> max.(x, 0.0)\n",
        "    )\n",
        "end\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6ByeJm-QJ7d",
        "outputId": "7d8c8d8a-f9d0-415d-e5ae-e69bc55bb421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rule_hybrid_H (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Barzilai–Borwein"
      ],
      "metadata": {
        "id": "3m28Iujy2Nyd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\alpha_k = \\frac{s_k^T s_k}{s_k^T y_k}  \n",
        "$$\n",
        "com\n",
        "$$\n",
        "s_k = x_k - x_{k-1} \\\\\n",
        "y_k = \\nabla f(x_k) - \\nabla f(x_{k-1})\n",
        "$$"
      ],
      "metadata": {
        "id": "Uf-ZA9c42ZAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# Regra passo espectral (Barzilai–Borwein)\n",
        "# ==========================================================\n",
        "function make_rule_spectral_W()\n",
        "    prev_W = nothing\n",
        "    prev_G = nothing\n",
        "\n",
        "    return (W, H, G, iter, alpha_prev) -> begin\n",
        "        alpha = alpha_prev\n",
        "        if prev_W !== nothing && prev_G !== nothing\n",
        "            s = W .- prev_W\n",
        "            y = G .- prev_G\n",
        "            den = sum(s .* y)\n",
        "            if den > 0 && isfinite(den)\n",
        "                alpha = clamp(sum(s .* s) / den, 1e-12, 1e12)\n",
        "            end\n",
        "        end\n",
        "        prev_W, prev_G = copy(W), copy(G)\n",
        "        return alpha\n",
        "    end\n",
        "end\n",
        "\n",
        "\n",
        "function make_rule_spectral_H()\n",
        "    prev_H = nothing\n",
        "    prev_G = nothing\n",
        "\n",
        "    return (W, H, G, iter, alpha_prev) -> begin\n",
        "        alpha = alpha_prev\n",
        "        if prev_H !== nothing && prev_G !== nothing\n",
        "            s = H .- prev_H\n",
        "            y = G .- prev_G\n",
        "            den = sum(s .* y)\n",
        "            if den > 0 && isfinite(den)\n",
        "                alpha = clamp(sum(s .* s) / den, 1e-12, 1e12)\n",
        "            end\n",
        "        end\n",
        "        prev_H, prev_G = copy(H), copy(G)\n",
        "        return alpha\n",
        "    end\n",
        "end\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVjs_vuDtJRK",
        "outputId": "c1276d36-74e7-4cda-a95c-553cf042bc70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "make_rule_spectral_H (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6XDhgUiPVeZ"
      },
      "source": [
        "## NMF Inversa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIWLW8RCJhq5",
        "outputId": "f9d819a8-762a-4a9e-a67c-fbf30bea9b4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nmf_inverse (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "function nmf_inverse(X, r; alpha=0.1, max_iter=max_iter_fixed, tol=tol_fixo)\n",
        "    m, n = size(X)\n",
        "    W = max.(rand(m, r), 1e-4)\n",
        "    H = max.(rand(r, n), 1e-4)\n",
        "    errors = Float64[]\n",
        "\n",
        "    t_start = time()\n",
        "    iters = 0\n",
        "\n",
        "    for iter = 1:max_iter\n",
        "        W_old = copy(W); H_old = copy(H)\n",
        "\n",
        "        A = H * H' + alpha*I(r)\n",
        "        W = X * H' * inv(A)\n",
        "        W .= max.(W, 0.0)\n",
        "        H .= H .* ((W' * X) ./ max.(W' * W * H, 1e-8))\n",
        "        H .= max.(H, 0.0)\n",
        "        push!(errors, norm(X - W*H))\n",
        "\n",
        "        if norm(W - W_old) / max(1, norm(W_old)) < tol &&\n",
        "          norm(H - H_old) / max(1, norm(H_old)) < tol\n",
        "            break\n",
        "        end\n",
        "    end\n",
        "\n",
        "    t_end = time()\n",
        "    total_time = t_end - t_start\n",
        "\n",
        "    return W, H, errors, total_time, iters\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkTyUPHZJnLF"
      },
      "source": [
        "## NMF Multiplicativo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1efOp22JqfG",
        "outputId": "c4b5e139-20e6-4ce3-a122-04046fdf0c98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nmf_multiplicative (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "function nmf_multiplicative(X, r; max_iter=max_iter_fixed, tol=tol_fixo)\n",
        "    m, n = size(X)\n",
        "    W = max.(rand(m, r), 1e-4)\n",
        "    H = max.(rand(r, n), 1e-4)\n",
        "    errors = Float64[]\n",
        "\n",
        "    t_start = time()\n",
        "    iters = 0\n",
        "\n",
        "    for iter = 1:max_iter\n",
        "        W_old = copy(W)\n",
        "        H_old = copy(H)\n",
        "\n",
        "        H .= H .* ((W' * X) ./ max.(W' * W * H, 1e-8))\n",
        "        H .= max.(H, 0.0)\n",
        "        W .= W .* ((X * H') ./ max.(W * (H * H'), 1e-8))\n",
        "        W .= max.(W, 0.0)\n",
        "\n",
        "        push!(errors, norm(X - W * H))\n",
        "        iters = iter\n",
        "\n",
        "        if norm(W - W_old) / max(1, norm(W_old)) < tol &&\n",
        "           norm(H - H_old) / max(1, norm(H_old)) < tol\n",
        "            break\n",
        "        end\n",
        "    end\n",
        "\n",
        "    t_end = time()\n",
        "    total_time = t_end - t_start\n",
        "    return W, H, errors, total_time, iters\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icLkSHEgRfgb"
      },
      "source": [
        "## Gradiente Projetado (gradiente do subproblema)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function line_search_segment!(\n",
        "    A_old, A_new, G, fixed_mat, f;\n",
        "    beta = 0.5,\n",
        "    sigma = 0.1,\n",
        "    theta_min = 1e-12,\n",
        "    monotone = true,\n",
        "    f_hist = nothing,\n",
        "    M_hist = 5 # número da memória\n",
        ")\n",
        "    # direcao\n",
        "    dW = A_new .- A_old\n",
        "    inner = sum(G .* dW)\n",
        "\n",
        "    # valor no ponto antigo\n",
        "    f_old = f(A_old, fixed_mat)\n",
        "\n",
        "    # se não-monotono, calcula máximo da janela\n",
        "    if monotone\n",
        "        f_ref = f_old\n",
        "    else\n",
        "        # inicializa histórico se necessário\n",
        "        if f_hist === nothing || isempty(f_hist)\n",
        "            f_hist = [f_old]\n",
        "        end\n",
        "\n",
        "        # referencia = maior valor recente\n",
        "        f_ref = maximum(f_hist)\n",
        "    end\n",
        "\n",
        "    # começa com passo cheio\n",
        "    theta = 1.0\n",
        "    f_new = f(A_new, fixed_mat)\n",
        "\n",
        "    # condicao geral\n",
        "    while f_new > f_ref - sigma * theta * inner\n",
        "        theta *= beta\n",
        "        if theta < theta_min\n",
        "            break\n",
        "        end\n",
        "        A_new .= A_old .+ theta .* dW\n",
        "        f_new = f(A_new, fixed_mat)\n",
        "    end\n",
        "\n",
        "    # se for não-monotono, atualiza histórico\n",
        "    if !monotone\n",
        "        push!(f_hist, f_new)\n",
        "        if length(f_hist) > M_hist\n",
        "            popfirst!(f_hist)  # mantém último M_hist valores\n",
        "        end\n",
        "    end\n",
        "\n",
        "    return A_new, theta, f_hist\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGek0SHeK8od",
        "outputId": "1ad6f4dd-7e93-453d-839b-c0d6edcbf0c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "line_search_segment! (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function projected_gradient_W(X, H, W0;\n",
        "    alpha_init = 1e-3,\n",
        "    lambda = 0.0,\n",
        "    tol = tol_fixo_sub,\n",
        "    max_iter = max_iter_fixed,\n",
        "    monotone = true,\n",
        "    alpha_rule_W = (W, H, G, iter, alpha_prev) -> alpha_prev\n",
        ")\n",
        "    W = copy(W0)\n",
        "    alpha = alpha_init\n",
        "    f_W(Wt,Ht) = 0.5 * norm(X - Wt*Ht)^2 + (lambda/2)*norm(Wt)^2\n",
        "    f_hist_W = nothing\n",
        "\n",
        "    for iter = 1:max_iter\n",
        "        W_old = copy(W)\n",
        "\n",
        "        GW = W * (H * H') .- X * H' .+ lambda .* W\n",
        "        alpha = alpha_rule_W(W, H, GW, iter, alpha)\n",
        "        W .= max.(W .- alpha .* GW, 0.0)\n",
        "\n",
        "        W_new, theta, new_f_hist_W = line_search_segment!(\n",
        "            W_old, W, GW, H, f_W;\n",
        "            monotone = monotone,\n",
        "            f_hist = f_hist_W,\n",
        "            M_hist = 5\n",
        "        )\n",
        "        W .= W_new\n",
        "        f_hist_W = new_f_hist_W\n",
        "\n",
        "        if norm(W - W_old) / max(1.0, norm(W_old)) < tol\n",
        "            return W, iter\n",
        "        end\n",
        "    end\n",
        "\n",
        "    return W, max_iter\n",
        "end\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# Subproblema para H\n",
        "# ==========================================================\n",
        "function projected_gradient_H(X, W, H0;\n",
        "    alpha_init = 1e-3,\n",
        "    lambda = 0.0,\n",
        "    tol = tol_fixo_sub,\n",
        "    max_iter = max_iter_fixed,\n",
        "    monotone = true,\n",
        "    alpha_rule_H = (W, H, G, iter, alpha_prev) -> alpha_prev\n",
        ")\n",
        "    H = copy(H0)\n",
        "    alpha = alpha_init\n",
        "    f_H(Ht, Wt) = 0.5 * norm(X - Wt * Ht)^2 + (lambda/2)*norm(Ht)^2\n",
        "    f_hist_H = nothing\n",
        "\n",
        "    for iter = 1:max_iter\n",
        "        H_old = copy(H)\n",
        "\n",
        "        GH = (W' * W) * H .- W' * X .+ lambda .* H\n",
        "        alpha = alpha_rule_H(W, H, GH, iter, alpha)\n",
        "        H .= max.(H .- alpha .* GH, 0.0)\n",
        "\n",
        "        H_new, theta, new_f_hist_H = line_search_segment!(\n",
        "            H_old, H, GH, W, f_H;\n",
        "            monotone = monotone,\n",
        "            f_hist = f_hist_H,\n",
        "            M_hist = 5\n",
        "        )\n",
        "        H .= H_new\n",
        "        f_hist_H = new_f_hist_H\n",
        "\n",
        "        if norm(H - H_old) / max(1.0, norm(H_old)) < tol\n",
        "            return H, iter\n",
        "        end\n",
        "    end\n",
        "\n",
        "    return H, max_iter\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-NQ_Hm5fOKa",
        "outputId": "f00b8881-889c-4350-8877-39f59b7a72b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "projected_gradient_H (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function nmf_gradient_projected(\n",
        "    X, r;\n",
        "    max_iter = max_iter_fixed,\n",
        "    tol = tol_fixo,\n",
        "    alpha_init = 1e-3,\n",
        "    lambda = 0.0,\n",
        "    sub_max_iter = max_iter_fixed,\n",
        "    sub_tol = tol_fixo_sub,\n",
        "    monotone = true,\n",
        "    alpha_rule_W = (W, H, G, i, a) -> a,\n",
        "    alpha_rule_H = (W, H, G, i, a) -> a\n",
        ")\n",
        "    m, n = size(X)\n",
        "    W = max.(rand(m, r), 1e-4)\n",
        "    H = max.(rand(r, n), 1e-4)\n",
        "    errors = Float64[]\n",
        "\n",
        "    t_start = time()\n",
        "    total_sub_iters = 0\n",
        "\n",
        "    for iter = 1:max_iter\n",
        "        W_old = copy(W)\n",
        "        H_old = copy(H)\n",
        "\n",
        "        # --- Atualização de W ---\n",
        "        W, iter_W = projected_gradient_W(X, H, W;\n",
        "            alpha_init = alpha_init,\n",
        "            lambda = lambda,\n",
        "            tol = sub_tol,\n",
        "            max_iter = sub_max_iter,\n",
        "            monotone = monotone,\n",
        "            alpha_rule_W = alpha_rule_W\n",
        "        )\n",
        "        total_sub_iters += iter_W\n",
        "\n",
        "        # --- Atualização de H ---\n",
        "        H, iter_H = projected_gradient_H(X, W, H;\n",
        "            alpha_init = alpha_init,\n",
        "            lambda = lambda,\n",
        "            tol = sub_tol,\n",
        "            max_iter = sub_max_iter,\n",
        "            monotone = monotone,\n",
        "            alpha_rule_H = alpha_rule_H\n",
        "        )\n",
        "        total_sub_iters += iter_H\n",
        "\n",
        "        push!(errors, norm(X - W * H))\n",
        "\n",
        "        deltaW = norm(W - W_old) / max(1.0, norm(W_old))\n",
        "        deltaH = norm(H - H_old) / max(1.0, norm(H_old))\n",
        "        if deltaW < tol && deltaH < tol\n",
        "            break\n",
        "        end\n",
        "    end\n",
        "\n",
        "    total_time = time() - t_start\n",
        "    return W, H, errors, total_time, total_sub_iters\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz1scpIXydon",
        "outputId": "73d2d9bf-5f3c-492f-c820-9ebbbc8dc2ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nmf_gradient_projected (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLTlTij0SpP3"
      },
      "outputs": [],
      "source": [
        "#function nmf_gradient_projected_(\n",
        "#  X, r;\n",
        "#  max_iter=max_iter_fixed,\n",
        "#  tol=tol_fixo,\n",
        "#  alpha_init=1e-3,\n",
        "#  lambda=0.0,\n",
        "#  alpha_rule_W = (W, H, GW, iter, alpha_prev) -> alpha_prev,\n",
        "#  alpha_rule_H = (W, H, GH, iter, alpha_prev) -> alpha_prev)\n",
        "#\n",
        "#    m, n = size(X)\n",
        "#    W = max.(rand(m, r), 1e-4)\n",
        "#    H = max.(rand(r, n), 1e-4)\n",
        "#    errors = Float64[]\n",
        "#\n",
        "#    alpha_W, alpha_H = alpha_init, alpha_init\n",
        "#\n",
        "#    t_start = time()\n",
        "#    iters = 0\n",
        "#\n",
        "#    for iter = 1:max_iter\n",
        "#        W_old = copy(W); H_old = copy(H)\n",
        "#\n",
        "#        # Atualização de W\n",
        "#        GW = W * (H * H') .- X * H' .+ lambda .* W\n",
        "#        alpha_W = alpha_rule_W(W, H, GW, iter, alpha_W)\n",
        "#        W .= max.(W .- alpha_W .* GW, 0.0)\n",
        "#\n",
        "#        # Atualização de H\n",
        "#        GH = (W' * W) * H .- W' * X .+ lambda .* H\n",
        "#        alpha_H = alpha_rule_H(W, H, GH, iter, alpha_H)\n",
        "#        H .= max.(H .- alpha_H .* GH, 0.0)\n",
        "#\n",
        "#        push!(errors, norm(X - W*H))\n",
        "#        iters = iter\n",
        "#\n",
        "#        if norm(W - W_old) / max(1, norm(W_old)) < tol &&\n",
        "#           norm(H - H_old) / max(1, norm(H_old)) < tol\n",
        "#            break\n",
        "#        end\n",
        "#    end\n",
        "#\n",
        "#    t_end = time()\n",
        "#    total_time = t_end - t_start\n",
        "#    return W, H, errors, total_time, iters\n",
        "#end\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALFN95BjxGKD"
      },
      "source": [
        "## Gradiente Projetado (atualização simultânea)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSTNfgrWggcG"
      },
      "source": [
        "$W^{t}$ e $H^{t}$ calculados simultaneamente. Espera-se terminar ambas $W^{t}$ e $H^{t}$ para calcular $W^{t+1}$ e $H^{t+1}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGYhrPKQxFi7",
        "outputId": "c7253cba-063f-419f-8da0-5c50be9f34ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nmf_pg_simultaneo (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "function nmf_pg_simultaneo(\n",
        "    X, r;\n",
        "    max_iter = max_iter_fixed,\n",
        "    tol = tol_fixo,\n",
        "    lambda = 0.0,\n",
        "    alpha_rule_W = (W,H,G,i,a)->a,\n",
        "    alpha_rule_H = (W,H,G,i,a)->a,\n",
        "    alphaW_init = 1e-3,\n",
        "    alphaH_init = 1e-3\n",
        ")\n",
        "    m, n = size(X)\n",
        "    W = max.(rand(m, r), 1e-4)\n",
        "    H = max.(rand(r, n), 1e-4)\n",
        "    errors = Float64[]\n",
        "    iters = 0\n",
        "\n",
        "    alphaW = alphaW_init\n",
        "    alphaH = alphaH_init\n",
        "\n",
        "    t_start = time()\n",
        "\n",
        "    for k = 1:max_iter\n",
        "        W_old = copy(W)\n",
        "        H_old = copy(H)\n",
        "\n",
        "        #task_W = Threads.@spawn begin\n",
        "            GW = W * (H * H') .- X * H' .+ lambda .* W\n",
        "            alphaW = alpha_rule_W(W, H, GW, k, alphaW)\n",
        "            W_new = max.(W .- alphaW .* GW, 0.0) #max.(W .- alphaW .* GW, 0.0), alphaW\n",
        "        #end\n",
        "\n",
        "        #task_H = Threads.@spawn begin\n",
        "            GH = (W' * W) * H .- W' * X .+ lambda .* H\n",
        "            alphaH = alpha_rule_H(W, H, GH, k, alphaH)\n",
        "            H_new = max.(H .- alphaH .* GH, 0.0) #max.(H .- alphaH .* GH, 0.0), alphaH\n",
        "        #end\n",
        "\n",
        "        #(W_new, alphaW) = fetch(task_W)\n",
        "        #(H_new, alphaH) = fetch(task_H)\n",
        "\n",
        "        W .= W_new\n",
        "        H .= H_new\n",
        "\n",
        "        push!(errors, norm(X - W * H))\n",
        "        iters = k\n",
        "\n",
        "        # Critério de parada\n",
        "        if norm(W - W_old) / max(1, norm(W_old)) < tol &&\n",
        "           norm(H - H_old) / max(1, norm(H_old)) < tol\n",
        "            break\n",
        "        end\n",
        "    end\n",
        "\n",
        "    total_time = time() - t_start\n",
        "    return W, H, errors, total_time, iters\n",
        "end\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvhkUW0snEW9"
      },
      "source": [
        "## Gradiente Projetado (atualização assíncrona)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVYxQjKxth0i"
      },
      "source": [
        "$W^{t}$ e $H^{t}$ calculados simultaneamente. Não se espera terminar ambas $W^{t}$ e $H^{t}$ para calcular $W^{t+1}$ e $H^{t+1}$. Nesse caso, pode ocorrer de várias iterações $W^t, ..., W^{t+1}$ usarem o mesmo $H^t$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBv71EkSnD1_",
        "outputId": "f1da663b-0f03-41bb-c9d5-3f8ca24e64a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nmf_pg_async (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "function nmf_pg_async(\n",
        "    X, r;\n",
        "    max_iter = 5000,\n",
        "    tol = 1e-4,\n",
        "    lambda = 0.0,\n",
        "    alpha_rule_W = (W,H,G,i,a)->a,\n",
        "    alpha_rule_H = (W,H,G,i,a)->a,\n",
        "    alphaW_init = 1e-3,\n",
        "    alphaH_init = 1e-3\n",
        ")\n",
        "    m, n = size(X)\n",
        "    W = max.(rand(m, r), 1e-4)\n",
        "    H = max.(rand(r, n), 1e-4)\n",
        "    errors = Float64[]\n",
        "\n",
        "    lockW = ReentrantLock()\n",
        "    lockH = ReentrantLock()\n",
        "\n",
        "    stop_flag = Ref(false)\n",
        "    iter = Ref(0)\n",
        "\n",
        "    alphaW = alphaW_init\n",
        "    alphaH = alphaH_init\n",
        "\n",
        "    t_start = time()\n",
        "\n",
        "    # Atualiza W\n",
        "    taskW = Threads.@spawn begin\n",
        "        while !stop_flag[] && iter[] < max_iter\n",
        "            iter[] += 1\n",
        "\n",
        "            lock(lockH)\n",
        "            local H_local = copy(H)\n",
        "            unlock(lockH)\n",
        "\n",
        "            lock(lockW)\n",
        "            GW = W * H_local * H_local' .- X * H_local' .+ lambda .* W\n",
        "            alphaW = alpha_rule_W(W, H_local, GW, iter[], alphaW)\n",
        "            W_new = max.(W .- alphaW .* GW, 0.0)\n",
        "            ΔW = norm(W_new - W) / max(1, norm(W))\n",
        "            W .= W_new\n",
        "            unlock(lockW)\n",
        "\n",
        "            if ΔW < tol\n",
        "                stop_flag[] = true\n",
        "            end\n",
        "        end\n",
        "    end\n",
        "\n",
        "    # Atualiza H\n",
        "    taskH = Threads.@spawn begin\n",
        "        while !stop_flag[] && iter[] < max_iter\n",
        "            lock(lockW)\n",
        "            local W_local = copy(W)\n",
        "            unlock(lockW)\n",
        "\n",
        "            lock(lockH)\n",
        "            GH = (W_local' * W_local) * H .- W_local' * X .+ lambda .* H\n",
        "            alphaH = alpha_rule_H(W_local, H, GH, iter[], alphaH)\n",
        "            H_new = max.(H .- alphaH .* GH, 0.0)\n",
        "            ΔH = norm(H_new - H) / max(1, norm(H))\n",
        "            H .= H_new\n",
        "            unlock(lockH)\n",
        "\n",
        "            if ΔH < tol\n",
        "                stop_flag[] = true\n",
        "            end\n",
        "        end\n",
        "    end\n",
        "\n",
        "    # Monitora erro periodicamente\n",
        "    while !stop_flag[] && iter[] < max_iter\n",
        "        sleep(0.01)\n",
        "        lock(lockW); lock(lockH)\n",
        "        push!(errors, norm(X - W * H))\n",
        "        unlock(lockH); unlock(lockW)\n",
        "    end\n",
        "\n",
        "    total_time = time() - t_start\n",
        "    fetch(taskW); fetch(taskH)\n",
        "\n",
        "    return W, H, errors, total_time, iter[]\n",
        "end\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWz8--_jnqX_",
        "outputId": "c91879fd-3e5e-45d2-dc89-0747834d8b36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threads disponíveis: 2\n",
            "Erro final = 2.433979704676242\n",
            "Tempo total = 2.834 s\n",
            "Iterações ≈ 1040\n"
          ]
        }
      ],
      "source": [
        "println(\"Threads disponíveis: \", Threads.nthreads())\n",
        "\n",
        "X = rand(10, 10)\n",
        "W, H, errors, t, iters = nmf_pg_async(X, 2;)\n",
        "println(\"Erro final = $(errors[end])\")\n",
        "println(\"Tempo total = $(round(t, digits=3)) s\")\n",
        "println(\"Iterações ≈ $iters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6uDFFYZSofZ"
      },
      "source": [
        "## Testes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEvZ4HjSGCwy",
        "outputId": "9c1c2454-5bdd-45e7-c799-2ebbee1a915e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dict{Symbol, Function} with 3 entries:\n",
              "  :gradiente_projetado_spectral_monotone     => #278\n",
              "  :multiplicativo                            => nmf_multiplicative\n",
              "  :gradiente_projetado_spectral_non_monotone => #276"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "dims = [100, 1000]\n",
        "r_values = [5, 10, 20]\n",
        "types = [:equal, :ill_conditioned]\n",
        "\n",
        "#dims = [1000]\n",
        "#r_values = [5, 100, 500]\n",
        "#types = [:equal, :ill_conditioned]\n",
        "\n",
        "models = Dict{Symbol, Function}(\n",
        "    #:inversa => nmf_inverse,\n",
        "\n",
        "    # ------------\n",
        "    :multiplicativo => nmf_multiplicative,\n",
        "\n",
        "    # ------------\n",
        "    #:gradiente_projetado => (X, r; kwargs...) -> nmf_gradient_projected( # passo fixo\n",
        "    #    X, r; alpha_rule_W = (W,H,G,i,a)->a, alpha_rule_H = (W,H,G,i,a)->a, kwargs...\n",
        "    #),\n",
        "\n",
        "    #:gradiente_projetado_lipschitz => (X, r; kwargs...) -> nmf_gradient_projected( # Lipschitz\n",
        "    #    X, r; alpha_rule_W = rule_lipschitz_W, alpha_rule_H = rule_lipschitz_H, kwargs...\n",
        "    #),\n",
        "\n",
        "    #:gradiente_projetado_armijo => (X, r; kwargs...) -> nmf_gradient_projected( # Armijo\n",
        "    #    X, r; alpha_rule_W = rule_armijo_W, alpha_rule_H = rule_armijo_H, kwargs...\n",
        "    #),\n",
        "\n",
        "    :gradiente_projetado_spectral_non_monotone => (X, r; kwargs...) -> nmf_gradient_projected(\n",
        "        X, r;\n",
        "        alpha_rule_W = make_rule_spectral_W(),\n",
        "        alpha_rule_H = make_rule_spectral_H(),\n",
        "        monotone = false,\n",
        "        kwargs...\n",
        "    ),\n",
        "\n",
        "    :gradiente_projetado_spectral_monotone => (X, r; kwargs...) -> nmf_gradient_projected(\n",
        "        X, r;\n",
        "        alpha_rule_W = make_rule_spectral_W(),\n",
        "        alpha_rule_H = make_rule_spectral_H(),\n",
        "        monotone = true,\n",
        "        kwargs...\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrizes aleatórias $X, W, H$"
      ],
      "metadata": {
        "id": "N0pA3twwII4a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zZpTP2rGWbj",
        "outputId": "0e29317e-2827-409c-a2d0-98b4240a0f8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Dimension = 100 | rank = 5 | type = equal ===\n",
            "gradiente_projetado_spectral_monotone → Erro final: 5.584407508727739 | Iterações: 458 | Tempo: 2.1641s\n",
            "multiplicativo → Erro final: 5.562848506313908 | Iterações: 1208 | Tempo: 0.0958s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 5.56443614237283 | Iterações: 1380 | Tempo: 0.1628s\n",
            "\n",
            "=== Dimension = 100 | rank = 5 | type = ill_conditioned ===\n",
            "gradiente_projetado_spectral_monotone → Erro final: 0.8376733478825847 | Iterações: 131 | Tempo: 0.0231s\n",
            "multiplicativo → Erro final: 0.7802298596042142 | Iterações: 1323 | Tempo: 0.099s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 0.7918765058414095 | Iterações: 219 | Tempo: 0.027s\n",
            "\n",
            "=== Dimension = 100 | rank = 10 | type = equal ===\n",
            "gradiente_projetado_spectral_monotone → Erro final: 5.177981052910148 | Iterações: 380 | Tempo: 0.057s\n",
            "multiplicativo → Erro final: 5.11541592492054 | Iterações: 1853 | Tempo: 0.1893s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 5.1430365624178025 | Iterações: 814 | Tempo: 0.1112s\n",
            "\n",
            "=== Dimension = 100 | rank = 10 | type = ill_conditioned ===\n",
            "gradiente_projetado_spectral_monotone → Erro final: 0.6478850301397664 | Iterações: 606 | Tempo: 0.092s\n",
            "multiplicativo → Erro final: 0.6303981278199581 | Iterações: 1121 | Tempo: 0.1145s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 0.6864558959743622 | Iterações: 277 | Tempo: 0.0432s\n",
            "\n",
            "=== Dimension = 100 | rank = 20 | type = equal ===\n",
            "gradiente_projetado_spectral_monotone → Erro final: 4.561857957623893 | Iterações: 654 | Tempo: 0.142s\n",
            "multiplicativo → Erro final: 4.469900214863834 | Iterações: 2225 | Tempo: 0.3472s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 4.550978096577875 | Iterações: 676 | Tempo: 0.138s\n",
            "\n",
            "=== Dimension = 100 | rank = 20 | type = ill_conditioned ===\n",
            "gradiente_projetado_spectral_monotone → Erro final: 0.6167910853814161 | Iterações: 228 | Tempo: 0.0486s\n",
            "multiplicativo → Erro final: 0.47243446818393714 | Iterações: 2422 | Tempo: 0.3836s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 0.6122965221998142 | Iterações: 294 | Tempo: 0.0635s\n",
            "\n",
            "=== Dimension = 1000 | rank = 5 | type = equal ===\n",
            "gradiente_projetado_spectral_monotone → Erro final: 18.920406799548783 | Iterações: 437 | Tempo: 8.2536s\n",
            "multiplicativo → Erro final: 18.898528642114243 | Iterações: 1741 | Tempo: 15.5317s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 18.908666866731828 | Iterações: 501 | Tempo: 7.8527s\n",
            "\n",
            "=== Dimension = 1000 | rank = 5 | type = ill_conditioned ===\n",
            "gradiente_projetado_spectral_monotone → Erro final: 3.1077861610832263 | Iterações: 575 | Tempo: 10.35s\n",
            "multiplicativo → Erro final: 3.105360583031367 | Iterações: 1591 | Tempo: 14.4386s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 3.1131249152055913 | Iterações: 275 | Tempo: 4.1021s\n",
            "\n",
            "=== Dimension = 1000 | rank = 10 | type = equal ===\n",
            "gradiente_projetado_spectral_monotone → Erro final: 18.80609403045957 | Iterações: 225 | Tempo: 4.6226s\n",
            "multiplicativo → Erro final: 18.72007781336441 | Iterações: 2292 | Tempo: 22.7028s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 18.778705094729737 | Iterações: 267 | Tempo: 4.9974s\n",
            "\n",
            "=== Dimension = 1000 | rank = 10 | type = ill_conditioned ===\n",
            "gradiente_projetado_spectral_monotone → Erro final: 3.095495383960728 | Iterações: 137 | Tempo: 2.8497s\n",
            "multiplicativo → Erro final: 3.066429432293836 | Iterações: 2432 | Tempo: 24.0462s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 3.078579304748678 | Iterações: 325 | Tempo: 5.5005s\n",
            "\n",
            "=== Dimension = 1000 | rank = 20 | type = equal ===\n",
            "gradiente_projetado_spectral_monotone → Erro final: 18.645547021705674 | Iterações: 173 | Tempo: 5.0226s\n",
            "multiplicativo → Erro final: 18.433128634750073 | Iterações: 2973 | Tempo: 35.432s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 18.50219952697651 | Iterações: 100364 | Tempo: 2002.6871s\n",
            "\n",
            "=== Dimension = 1000 | rank = 20 | type = ill_conditioned ===\n",
            "gradiente_projetado_spectral_monotone → Erro final: 3.051395045459264 | Iterações: 201 | Tempo: 5.3664s\n",
            "multiplicativo → Erro final: 2.996156801895114 | Iterações: 2588 | Tempo: 30.5689s\n",
            "gradiente_projetado_spectral_non_monotone → Erro final: 3.050729670430564 | Iterações: 100159 | Tempo: 2032.9321s\n"
          ]
        }
      ],
      "source": [
        "for n in dims\n",
        "    for r in r_values\n",
        "        if r > n\n",
        "            continue\n",
        "        end\n",
        "\n",
        "        for t in types\n",
        "            println(\"\\n=== Dimension = $n | rank = $r | type = $t ===\")\n",
        "            X = generate_matrix(n,n, type=t)\n",
        "\n",
        "            for (name, model) in models\n",
        "                W, H, err, total_time, iters = model(X, r)\n",
        "\n",
        "                erro_final = isempty(err) ? NaN : err[end]\n",
        "                tempo = round(total_time, digits=4)\n",
        "\n",
        "                println(\"$(string(name)) → Erro final: $erro_final | Iterações: $iters | Tempo: $(tempo)s\")\n",
        "            end\n",
        "        end\n",
        "    end\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Teste exato $X = WH$"
      ],
      "metadata": {
        "id": "7p8B2s6rLtxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dims = [10, 100, 1000]\n",
        "r_values = [10]\n",
        "types = [:equal]\n",
        "\n",
        "for n in dims\n",
        "    for r in r_values\n",
        "        if r > n\n",
        "            continue\n",
        "        end\n",
        "\n",
        "        for t in types\n",
        "            println(\"\\n=== Dimension = $n | rank = $r | type = $t ===\")\n",
        "            X, W_true, H_true = generate_X_WH(n, n, r; type=t)\n",
        "\n",
        "            for (name, model) in models\n",
        "                W, H, err, total_time, iters = model(X, r)\n",
        "\n",
        "                erro_final = isempty(err) ? NaN : err[end]\n",
        "                tempo = round(total_time, digits=4)\n",
        "\n",
        "                err_WH = norm(X - W * H) / norm(X)\n",
        "                err_W  = norm(W - W_true) / norm(W_true)\n",
        "                err_H  = norm(H - H_true) / norm(H_true)\n",
        "                println(\"$(string(name)) → Erro(X): $(round(err_WH,digits=6)) | Erro(W): $(round(err_W,digits=6)) | Erro(H): $(round(err_H,digits=6)) | Iterações: $iters | Tempo: $(tempo)s\")\n",
        "            end\n",
        "        end\n",
        "    end\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSiYKxSIL_VN",
        "outputId": "8554a4b6-43e8-41c4-cc79-e3c31e5bd43e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Dimension = 10 | rank = 10 | type = equal ===\n",
            "gradiente_projetado_spectral → Erro(X): 0.000567 | Erro(W): 0.816484 | Erro(H): 2.230003 | Iterações: 6959 | Tempo: 0.4986s\n",
            "multiplicativo → Erro(X): 0.0028 | Erro(W): 1.543776 | Erro(H): 0.794663 | Iterações: 395 | Tempo: 0.0077s\n",
            "\n",
            "=== Dimension = 100 | rank = 10 | type = equal ===\n",
            "gradiente_projetado_spectral → Erro(X): 0.080456 | Erro(W): 0.902822 | Erro(H): 10.946179 | Iterações: 1444 | Tempo: 0.3879s\n",
            "multiplicativo → Erro(X): 0.010508 | Erro(W): 5.700981 | Erro(H): 0.898967 | Iterações: 1803 | Tempo: 0.276s\n",
            "\n",
            "=== Dimension = 1000 | rank = 10 | type = equal ===\n",
            "gradiente_projetado_spectral → Erro(X): 0.08885 | Erro(W): 0.966269 | Erro(H): 30.748941 | Iterações: 2459 | Tempo: 84.6612s\n",
            "multiplicativo → Erro(X): 0.011372 | Erro(W): 20.149818 | Erro(H): 0.970488 | Iterações: 1816 | Tempo: 25.6304s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "id": "sYMC_nUdJBSC",
        "outputId": "ca80a8da-f923-4658-c23c-4ae6523e88ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===============================\n",
            "=== Dimensão = 200 | rank = 10 | tipo = uniform ===\n",
            "===============================\n",
            "1, "
          ]
        },
        {
          "output_type": "error",
          "ename": "LoadError",
          "evalue": "InterruptException:",
          "traceback": [
            "InterruptException:",
            "",
            "Stacktrace:",
            "  [1] \u001b[0m\u001b[1mGenericMemory\u001b[22m",
            "\u001b[90m    @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mboot.jl:516\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
            "  [2] \u001b[0m\u001b[1mnew_as_memoryref\u001b[22m",
            "\u001b[90m    @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mboot.jl:535\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
            "  [3] \u001b[0m\u001b[1mArray\u001b[22m",
            "\u001b[90m    @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mboot.jl:582\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
            "  [4] \u001b[0m\u001b[1mArray\u001b[22m",
            "\u001b[90m    @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mboot.jl:592\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
            "  [5] \u001b[0m\u001b[1mArray\u001b[22m",
            "\u001b[90m    @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mboot.jl:599\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
            "  [6] \u001b[0m\u001b[1msimilar\u001b[22m",
            "\u001b[90m    @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mabstractarray.jl:868\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
            "  [7] \u001b[0m\u001b[1msimilar\u001b[22m",
            "\u001b[90m    @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mabstractarray.jl:867\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
            "  [8] \u001b[0m\u001b[1msimilar\u001b[22m",
            "\u001b[90m    @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mbroadcast.jl:224\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
            "  [9] \u001b[0m\u001b[1msimilar\u001b[22m",
            "\u001b[90m    @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mbroadcast.jl:223\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
            " [10] \u001b[0m\u001b[1mcopy\u001b[22m",
            "\u001b[90m    @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mbroadcast.jl:897\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
            " [11] \u001b[0m\u001b[1mmaterialize\u001b[22m",
            "\u001b[90m    @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mbroadcast.jl:872\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
            " [12] \u001b[0m\u001b[1mprojected_gradient_H\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mX\u001b[39m::\u001b[0mMatrix\u001b[90m{Float64}\u001b[39m, \u001b[90mW\u001b[39m::\u001b[0mMatrix\u001b[90m{Float64}\u001b[39m, \u001b[90mH0\u001b[39m::\u001b[0mMatrix\u001b[90m{Float64}\u001b[39m; \u001b[90malpha_init\u001b[39m::\u001b[0mFloat64, \u001b[90mlambda\u001b[39m::\u001b[0mFloat64, \u001b[90mtol\u001b[39m::\u001b[0mFloat64, \u001b[90mmax_iter\u001b[39m::\u001b[0mInt64, \u001b[90malpha_rule_H\u001b[39m::\u001b[0mvar\"#77#86\"\u001b[0m\u001b[1m)\u001b[22m",
            "\u001b[90m    @\u001b[39m \u001b[35mMain\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mIn[11]:48\u001b[24m\u001b[39m",
            " [13] \u001b[0m\u001b[1mnmf_gradient_projected\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mX\u001b[39m::\u001b[0mMatrix\u001b[90m{Float64}\u001b[39m, \u001b[90mr\u001b[39m::\u001b[0mInt64; \u001b[90mmax_iter\u001b[39m::\u001b[0mInt64, \u001b[90mtol\u001b[39m::\u001b[0mFloat64, \u001b[90malpha_init\u001b[39m::\u001b[0mFloat64, \u001b[90mlambda\u001b[39m::\u001b[0mFloat64, \u001b[90msub_max_iter\u001b[39m::\u001b[0mInt64, \u001b[90msub_tol\u001b[39m::\u001b[0mFloat64, \u001b[90malpha_rule_W\u001b[39m::\u001b[0mFunction, \u001b[90malpha_rule_H\u001b[39m::\u001b[0mFunction\u001b[0m\u001b[1m)\u001b[22m",
            "\u001b[90m    @\u001b[39m \u001b[35mMain\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mIn[12]:34\u001b[24m\u001b[39m",
            " [14] \u001b[0m\u001b[1m(::var\"#74#84\")\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mX\u001b[39m::\u001b[0mMatrix\u001b[90m{Float64}\u001b[39m, \u001b[90mr\u001b[39m::\u001b[0mInt64\u001b[0m\u001b[1m)\u001b[22m",
            "\u001b[90m    @\u001b[39m \u001b[35mMain\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mIn[17]:16\u001b[24m\u001b[39m",
            " [15] top-level scope",
            "\u001b[90m    @\u001b[39m \u001b[90m\u001b[4mIn[20]:25\u001b[24m\u001b[39m"
          ]
        }
      ],
      "source": [
        "num_trials = 10\n",
        "dims = [200]\n",
        "r = 10\n",
        "type = :uniform\n",
        "\n",
        "for n in dims\n",
        "    println(\"\\n===============================\")\n",
        "    println(\"=== Dimensão = $n | rank = $r | tipo = $type ===\")\n",
        "    println(\"===============================\")\n",
        "\n",
        "    # inicializa dicionários\n",
        "    errors = Dict(model => [] for model in keys(models))\n",
        "    times  = Dict(model => Float64[] for model in keys(models))\n",
        "    iters  = Dict(model => Int[] for model in keys(models))\n",
        "\n",
        "    # ----------------------------------------------------------\n",
        "    # Loop principal\n",
        "    # ----------------------------------------------------------\n",
        "    for trial in 1:num_trials\n",
        "        print(\"$trial, \")\n",
        "        X = generate_matrix(n, n, type=type)\n",
        "\n",
        "        for (name, model) in models\n",
        "            t_start = time()\n",
        "            _, _, err = model(X, r)\n",
        "            t_end = time()\n",
        "\n",
        "            push!(errors[name], err)\n",
        "            push!(times[name], t_end - t_start)\n",
        "            push!(iters[name], length(err))\n",
        "        end\n",
        "    end\n",
        "    println(\"\\n\")\n",
        "\n",
        "    # ----------------------------------------------------------\n",
        "    # Estatísticas de erro final\n",
        "    # ----------------------------------------------------------\n",
        "    println(\"=== Estatísticas do erro final (n = $n) ===\")\n",
        "    for name in keys(models)\n",
        "        final_errs = [isempty(e) ? NaN : e[end] for e in errors[name]]\n",
        "        media = mean(skipmissing(final_errs))\n",
        "        desvio = std(skipmissing(final_errs))\n",
        "        @printf(\"%-35s → Média = %.6f | Std = %.6f\\n\", string(name), media, desvio)\n",
        "    end\n",
        "\n",
        "    # ----------------------------------------------------------\n",
        "    # Estatísticas de tempo\n",
        "    # ----------------------------------------------------------\n",
        "    println(\"\\n=== Estatísticas de tempo (n = $n) ===\")\n",
        "    for name in keys(models)\n",
        "        media = mean(times[name])\n",
        "        desvio = std(times[name])\n",
        "        @printf(\"%-35s → Média = %.6fs | Std = %.6fs\\n\", string(name), media, desvio)\n",
        "    end\n",
        "\n",
        "    # ----------------------------------------------------------\n",
        "    # Estatísticas de iterações\n",
        "    # ----------------------------------------------------------\n",
        "    println(\"\\n=== Estatísticas do número de iterações (n = $n) ===\")\n",
        "    for name in keys(models)\n",
        "        media = mean(iters[name])\n",
        "        desvio = std(iters[name])\n",
        "        @printf(\"%-35s → Média = %.2f | Std = %.2f\\n\", string(name), media, desvio)\n",
        "    end\n",
        "end\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEtJNu32HDTx"
      },
      "source": [
        "# NMF package"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## https://nimfa.biolab.si/nimfa.datasets.html"
      ],
      "metadata": {
        "id": "VAKuExZ3sqJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRHpk7ZNHCr2",
        "outputId": "fce2e77f-cab5-4adc-82d3-d0a34b716598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m\u001b[1m     Cloning\u001b[22m\u001b[39m git-repo `https://github.com/JuliaStats/NMF.jl`\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaStats/NMF.jl`\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m NonNegLeastSquares ─ v0.4.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m RandomizedLinAlg ─── v0.1.0\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.11/Project.toml`\n",
            "  \u001b[90m[6ef6ca0d] \u001b[39m\u001b[92m+ NMF v1.0.3 `https://github.com/JuliaStats/NMF.jl#master`\u001b[39m\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.11/Manifest.toml`\n",
            "  \u001b[90m[6ef6ca0d] \u001b[39m\u001b[92m+ NMF v1.0.3 `https://github.com/JuliaStats/NMF.jl#master`\u001b[39m\n",
            "  \u001b[90m[b7351bd1] \u001b[39m\u001b[92m+ NonNegLeastSquares v0.4.1\u001b[39m\n",
            "  \u001b[90m[0448d7d9] \u001b[39m\u001b[92m+ RandomizedLinAlg v0.1.0\u001b[39m\n",
            "\u001b[92m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "   4984.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mNonNegLeastSquares\u001b[39m\n",
            "   3881.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mRandomizedLinAlg\u001b[39m\n",
            "  42869.2 ms\u001b[32m  ✓ \u001b[39mNMF\n",
            "  3 dependencies successfully precompiled in 55 seconds. 490 already precompiled.\n"
          ]
        }
      ],
      "source": [
        "using Pkg\n",
        "Pkg.add(url=\"https://github.com/JuliaStats/NMF.jl\")\n",
        "using NMF\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "http://mtm.ufsc.br/~douglas/2019.1/MTM5813/matlab/"
      ],
      "metadata": {
        "id": "w6ugqYQseZlO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "41lLifSQeaFR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_6XDhgUiPVeZ",
        "KkTyUPHZJnLF",
        "ALFN95BjxGKD",
        "vvhkUW0snEW9"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Julia",
      "name": "julia"
    },
    "language_info": {
      "name": "julia"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}